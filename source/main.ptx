<?xml version="1.0" encoding="UTF-8"?>
<pretext xml:lang="en-US">
  <book xml:id="ldlos">
    <title>Lies, Damned Lies, or Statistics</title>
    <subtitle>How to Tell the Truth with Statistics</subtitle>
    <author>
      <personname>
        <firstname>Jonathan</firstname>
        <middlename>A.</middlename>
        <surname>Poritz</surname>
      </personname>
    </author>

    <frontmatter>
      <preface xml:id="release-notes">
        <title>Release Notes</title>
        <p/>
      </preface>
      <preface xml:id="preface">
        <title>Preface</title>
        <p/>
      </preface>
    </frontmatter>

    <part xml:id="part-DS">
      <title>Descriptive Statistics</title>

      <chapter xml:id="chap-1VS">
        <title>One-Variable Statistics: Basics</title>
        <section xml:id="sec-TIPVS">
          <title>Terminology: Individuals/Population/Variables/Samples</title>
          <p>
            Oddly enough, it is often a lack of clarity about <em>who</em> [or <em>what</em>]
            <em>you are looking at</em> which makes a lie out of statistics. Here are the
            terms, then, to keep straight:
          </p>

          <definition xml:id="def-individual-population">
            <idx>individual in a statistical study</idx>
            <idx>population of a statistical study</idx>
            <statement>
              <p>
                The units which are the objects of a statistical study are called the
                <term>individuals</term> in that study,
                while the collection of all such individuals is called the
                <term>population</term> of the study.
              </p>
            </statement>
          </definition>

          <p>
            Note that while the term <q>individuals</q> sounds like it is talking about
            people, the individuals in a study could be things, even abstract things like
            events.
          </p>

          <example xml:id="eg-votersind">
            <title>Individuals in Election Study</title>
            <idx>voters</idx>
            <statement>
              <p>
                The individuals in a study about a democratic election might be
                <em>the voters</em>. But if you are going to make an accurate
                prediction of who will win the election, it is important to be more precise
                about what exactly is the population of all of those individuals [voters]
                that you intend to study: is it <em>all eligible voters</em>, <em>all
                registered voters</em>, <em>the people who actually voted</em>, <em>etc.</em>
              </p>
            </statement>
          </example>

          <example xml:id="eg-flipsind">
            <title>Individuals in Coin Flip Study</title>
            <statement>
              <p>
                If you want to study if a coin is <q>fair</q> or not, you would flip it repeatedly.
                The individuals would then be <em>flips of that coin</em>, and the population
                might be something like <em>all the flips ever done in the past and all that
                will ever be done in the future</em>. These individuals are quite abstract, and
                in fact it is impossible ever to get your hands on all of them (the ones in the
                future, for example).
              </p>
            </statement>
          </example>

          <example xml:id="eg-studentstakingtestsind">
            <title>Individuals in Homework Study</title>
            <statement>
              <p>
                Suppose we're interested in studying whether doing more homework helps students
                do better in their studies. So shouldn't the individuals be the students?
                Well, which students? How about we look only at college students. Which
                college students? OK, how about students at 4-year colleges and universities
                in the United States, over the last five years<mdash/>after all, things might be
                different in other countries and other historical periods.
              </p>
              <p>
                Wait, a particular student might sometimes do a lot of homework and sometimes
                do very little. And what exactly does <q>do better in their studies</q> mean? So
                maybe we should look at each student in each class they take, then we can look
                at the homework they did for that class and the success they had in it.
              </p>
              <p>
                Therefore, the individuals in this study would be <em>individual experiences
                that students in US 4-year colleges and universities had in the last five
                years</em>, and population of the study would essentially be the collection of all
                the names on all class rosters of courses in the last five years at all US
                4-year colleges and universities.
              </p>
            </statement>
          </example>

          <p>
            When doing an actual scientific study, we are usually not interested so much
            in the individuals themselves, but rather in
          </p>

          <definition xml:id="def-variable">
            <idx>variable</idx>
            <idx><h>variable</h><h>categorical</h></idx>
            <idx><h>variable</h><h>quantitative</h></idx>
            <statement>
              <p>
                A <term>variable</term> in a statistical study is the answer of a question the
                researcher is asking about each individual. There are two types:
                <ul>
                  <li>
                    <p>
                      A <term>categorical variable</term> is one whose
                      values have a finite number of possibilities.
                    </p>
                  </li>
                  <li>
                    <p>
                      A <term>quantitative variable</term> is one whose
                      values are numbers (so, potentially an infinite number of possibilities).
                    </p>
                  </li>
                </ul>
              </p>
            </statement>
          </definition>

          <p>
            The variable is something which (as the name says) <em>varies</em>, in the sense
            that it can have a different value for each individual in the population
            (although that is not necessary).
          </p>

          <example xml:id="eg-votersvar">
            <title>Variable in Election Study</title>
            <statement>
              <p>
                In <xref ref="eg-votersind"/>, the variable most likely would be <em>who they
                voted for</em>, a categorical variable with only possible values <q>Mickey Mouse</q>
                or <q>Daffy Duck</q> (or whoever the names on the ballot were).
              </p>
            </statement>
          </example>

          <example xml:id="eg-flipsvar">
            <title>Variable in Coin Flip Study</title>
            <statement>
              <p>
                In <xref ref="eg-flipsind"/>, the variable most likely would be <em>what face
                of the coin was facing up after the flip</em>, a categorical variable with values
                <q>heads</q> and <q>tails.</q>
              </p>
            </statement>
          </example>

          <example xml:id="eg-studentstakingtestsvar">
            <title>Variables in Homework Study</title>
            <statement>
              <p>
                There are several variables we might use in
                <xref ref="eg-studentstakingtestsind"/>. One might be <em>how many homework
                problems did the student do in that course</em>. Another could be <em>how many
                hours total did the student spend doing homework over that whole semester, for
                that course</em>. Both of those would be quantitative
                variables.
              </p>
              <p>
                A categorical variable for the same
                population would be <em>what letter grade did the student get in the course</em>,
                which has possible values <term>A</term>, <term>A-</term>, <term>B+</term>, <ellipsis/>, <term>D-</term>, <term>F</term>.
              </p>
            </statement>
          </example>

          <p>
            In many [most?] interesting studies, the population is too large for it to be
            practical to go observe the values of some interesting variable. Sometimes it
            is not just impractical, but actually impossible<mdash/>think of the example we gave
            of all the flips of the coin, even the ones in the future. So instead, we
            often work with
          </p>

          <definition xml:id="def-sample">
            <idx>sample</idx>
            <statement>
              <p>
                A <term>sample</term> is a subset of a population under study.
              </p>
            </statement>
          </definition>

          <p>
            Often we use the variable
            <m>N</m> to indicate the
            size of a whole population and the variable
            <m>n</m> for the size of a sample;
            as we have said, usually <m>n \lt N</m>.
          </p>

          <p>
            Later we shall discuss how to pick a good sample, and how much we can learn
            about a population from looking at the values of a variable of interest only
            for the individuals in a sample. For the rest of this chapter, however, let's
            just consider what to do with these sample values.
          </p>
        </section>
        <section xml:id="sec-VRoDICV">
          <title>Visual Representation of Data, I: Categorical Variables</title>
          <p>
            Suppose we have a population and variable in which we are interested. We get
            a sample, which could be large or small, and look at the values of our
            variable for the individuals in that sample. We shall informally refer to
            this collection of values as a <term>dataset</term>.
          </p>

          <p>
            In this section, we suppose also that the variable we are looking at is
            categorical. Then we can summarize the dataset by telling which categorical
            values did we see for the individuals in the sample, and how often we saw
            those values.
          </p>

          <p>
            There are two ways we can make pictures of this information: <em>bar charts</em>
            and <em>pie charts</em>.
          </p>
          <subsection xml:id="ssec-BCIFC">
            <title>Bar Charts I: Frequency Charts</title>
            <p>
              We can take the values which we saw for individuals in the sample along the
              <m>x</m>-axis of a graph, and over each such label make a box whose height indicates
              how many individuals had that value<mdash/>the <term>frequency</term> of occurrence of
              that value.
            </p>

            <p>
              This is called a <term>bar chart</term>. As with all graphs, you
              should <em>always label all axes.</em> The <m>x</m>-axis will be labeled with some
              description of the variable in question, the <m>y</m>-axis label will always be
              <q>frequency</q> (or some synonym like <q>count</q> or <q>number of times</q>).
            </p>

            <example xml:id="eg-flipsbarchartfreq">
              <title>Frequency Bar Chart for Coin Flips</title>
              <statement>
                <p>
                  In <xref ref="eg-flipsvar"/>, suppose we took a sample consisting of the
                  next 10 flips of our coin. Suppose further that 4 of the flips came up
                  heads<mdash/>write it as <q>H</q><mdash/>and 6 came up tails, T. Then the corresponding
                  bar chart would show bars for H with height 4 and T with height 6.
                </p>
                <p>
                  <em>[Figure showing frequency bar chart with H at 4 and T at 6 would go here]</em>
                </p>
              </statement>
            </example>
          </subsection>
          <subsection xml:id="ssec-BCIIRFC">
            <title>Bar Charts II: Relative Frequency Charts</title>
            <p>
              There is a variant of the above kind of bar chart which actually looks nearly
              the same but changes the labels on the <m>y</m>-axis. That is, instead of making
              the height of each bar be how many times each categorical value occurred, we
              could make it be <em>what fraction of the sample had that categorical
              value</em><mdash/>the <term>relative frequency</term>. This fraction is often displayed as a
              percentage.
            </p>

            <example xml:id="eg-flipsbarchartrelfreq">
              <title>Relative Frequency Bar Chart for Coin Flips</title>
              <statement>
                <p>
                  The relative frequency version of the above bar chart in
                  <xref ref="eg-flipsbarchartfreq"/> would show bars for H at height 0.4 (or 40%)
                  and T at height 0.6 (or 60%).
                </p>
                <p>
                  <em>[Figure showing relative frequency bar chart would go here]</em>
                </p>
              </statement>
            </example>
          </subsection>
          <subsection xml:id="ssec-BCIIIC">
            <title>Bar Charts III: Cautions</title>
            <p>
              Notice that with bar charts (of either frequency or relative frequency) the
              variable values along the <m>x</m>-axis <em>can appear in any order whatsoever</em>.
              This means that any conclusion you draw from looking at the bar chart must
              not depend upon that order. For example, it would be foolish to say that the
              graph in <xref ref="eg-flipsbarchartfreq"/> <q>shows an increasing
              trend,</q> since it would make just as much sense to put the bars in the other
              order and then <q>show a decreasing trend</q><mdash/>both are meaningless.
            </p>

            <p>
              For relative frequency bar charts, in particular, note that the total of
              the heights of all the bars must be <m>1</m> (or <m>100\%</m>). If it is more, something
              is weird; if it is less, some data has been lost.
            </p>

            <p>
              Finally, it makes sense for both kinds of bar charts for the <m>y</m>-axis to
              run from the logical minimum to maximum. For frequency charts, this means it
              should go from <m>0</m> to <m>n</m> (the sample size). For relative frequency charts,
              it should go from <m>0</m> to <m>1</m> (or <m>100\%</m>). Skimping on how much of this
              appropriate <m>y</m>-axis is used is a common trick to lie with statistics.
            </p>

            <example xml:id="eg-flipsbarchartrelfreqbadyaxis">
              <title>Misleading Bar Chart with Bad Y-Axis</title>
              <statement>
                <p>
                  The coin we looked at in <xref ref="eg-flipsbarchartfreq"/> and
                  <xref ref="eg-flipsbarchartrelfreq"/> could well be a fair coin<mdash/>it didn't
                  show exactly half heads and half tails, but it was pretty close. Someone who
                  was trying to claim, deceptively, that the coin was not fair might have shown
                  only a portion of the <m>y</m>-axis, making the difference appear much more dramatic.
                </p>
                <p>
                  <em>[Figure showing bar chart with restricted y-axis from 0.3 to 0.6 would go here]</em>
                </p>
                <p>
                  This is actually, in a strictly technical sense, a correct graph. But, looking
                  at it, one might conclude that T seems to occur more than twice as often as
                  H, so the coin is probably not fair<ellipsis/> until a careful examination of the
                  <m>y</m>-axis shows that even though the bar for T is more than twice as high as the
                  bar for H, that is an artifact of how much of the <m>y</m>-axis is being shown.
                </p>
              </statement>
            </example>

            <p>
              In summary, bar charts actually don't have all that much use in sophisticated
              statistics, but are extremely common in the popular press (and on web sites
              and so on).
            </p>
          </subsection>
          <subsection xml:id="ssec-PC">
            <title>Pie Charts</title>
            <p>
              Another way to make a picture with categorical data is to use the fractions
              from a relative frequency bar chart, but not for the heights of bars, instead
              for the sizes of wedges of a pie.
            </p>

            <example xml:id="eg-flipspiechart">
              <title>Pie Chart for Coin Flips</title>
              <statement>
                <p>
                  Here's a pie chart with the relative frequency data from
                  <xref ref="eg-flipsbarchartrelfreq"/>. It would show a pie divided into two
                  wedges: one for H taking up 40% of the pie, and one for T taking up 60%.
                </p>
                <p>
                  <em>[Figure showing pie chart would go here]</em>
                </p>
              </statement>
            </example>

            <p>
              Pie charts are widely used, but actually they are almost never a good choice.
              In fact, do an Internet search for the phrase <q>pie charts are bad</q> and there
              will be many hits. Many of the arguments are quite insightful.
            </p>

            <p>
              When you see a pie chart, it is either an attempt (misguided, though) by
              someone to be folksy and friendly, or it is a sign that the author is quite
              unsophisticated with data visualization, or, worst of all, it might be a sign
              that the author is trying to use mathematical methods in a deceptive way.
            </p>

            <p>
              In addition, all of the cautions we mentioned above for bar charts of
              categorical data apply, mostly in exactly the same way, for pie charts.
            </p>
          </subsection>
        </section>
        <section xml:id="sec-VRoDIIQV">
          <title>Visual Representation of Data, II: Quantitative Variables</title>
          <p>
            Now suppose we have a population and <em>quantitative</em>
            variable in which we
            are interested. We get a sample, which could be large or small, and look at
            the values of our variable for the individuals in that sample. There are
            two ways we tend to make pictures of datasets like this: <em>stem-and-leaf
            plots</em> and <em>histograms</em>.
          </p>
          <subsection xml:id="ssec-SalP">
            <title>Stem-and-leaf Plots</title>
            <idx>stem, in stemplot</idx>
            <idx>leaf, in stemplot</idx>
            <idx>stem-and-leaf plot, stemplot</idx>
            <p>
              One somewhat old-fashioned way to handle a modest amount of quantitative data
              produces something between simply a list of all the data values and a graph.
              It's not a bad technique to know about in case one has to write down a dataset
              by hand, but very tedious <mdash/> and quite unnecessary, if one uses modern
              electronic tools instead <mdash/> if the dataset has more than a couple dozen values.
              The easiest case of this technique is where the data are all whole numbers in
              the range <m>0-99</m>. In that case, one can take off the tens place of each
              number <mdash/> call it the <term>stem</term> <mdash/> and put it on the
              left side of a vertical bar, and then line up all the ones places <mdash/> each is a
              <term>leaf</term> <mdash/> to the right of that stem. The whole
              thing is called a <term>stem-and-leaf plot</term>
              or, sometimes, just a <term>stemplot</term>.
            </p>

            <p>
              It's important not to skip any stems which are in the middle of the dataset,
              even if there are no corresponding leaves. It is also a good idea to allow
              repeated leaves, if there are repeated numbers in the dataset, so that the
              length of the row of leaves will give a good representation of how much
              data is in that general group of data values.
            </p>

            <example xml:id="eg-stemandleafplot">
              <idx>stem-and-leaf plot, stemplot</idx>
              <statement>
                <p>
                  Here is a list of the scores of 30 students on a statistics test:
                </p>
                <me>
                  \begin{matrix}
                  86 &amp; 80 &amp; 25 &amp; 77 &amp; 73 &amp; 76 &amp; 88 &amp; 90 &amp; 69 &amp; 93\\
                  90 &amp; 83 &amp; 70 &amp; 73 &amp; 73 &amp; 70 &amp; 90 &amp; 83 &amp; 71 &amp; 95\\
                  40 &amp; 58 &amp; 68 &amp; 69 &amp; 100 &amp; 78 &amp; 87 &amp; 25 &amp; 92 &amp; 74
                  \end{matrix}
                </me>
                <p>
                  As we said, using the tens place (and the hundreds place as well, for the
                  data value <m>100</m>) as the stem and the ones place as the leaf, we get
                </p>
                <p>
                  <em>[Table showing stem-and-leaf plot of students' scores, Key: <m>1 | 7 = 17</m> would go here]</em>
                </p>
              </statement>
            </example>

            <p>
              One nice feature stem-and-leaf plots have is that <em>they contain
              all of the data values</em>, they do not lose anything (unlike our next
              visualization method, for example).
            </p>
          </subsection>
          <subsection xml:id="ssec-FHistograms">
            <title>[Frequency] Histograms</title>
            <idx>histogram</idx>
            <idx>bins, in a histogram</idx>
            <idx>classes, in a histogram</idx>
            <p>
              The most important visual representation of quantitative data is a
              <term>histogram</term>. Histograms actually look a lot like a stem-and-leaf plot,
              except turned on its side and with the row of numbers turned into a vertical
              bar, like a bar graph. The height of each of these bars would be how many
            </p>

            <p>
              Another way of saying that is that we would be making bars whose heights were
              determined by how many scores were in each group of ten. Note there is still
              a question of into which bar a value right on the edge would count: <em>e.g.,</em>
              does the data value <m>50</m> count in the bar to the left of that number, or the
              bar to the right? It doesn't actually matter which side, but it is important
              to state which choice is being made.
            </p>

            <example xml:id="eg-scoreshistbytens">
              <idx>histogram</idx>
              <statement>
                <p>
                  Continuing with the score data in Example <xref ref="eg-stemandleafplot"/> and
                  putting all data values <m>x</m> satisfying <m>20\le x&lt;30</m> in the first bar,
                  values <m>x</m> satisfying <m>30\le x&lt;40</m> in the second,
                  values <m>x</m> satisfying <m>40\le x&lt;50</m> in the third, <em>etc.</em> <mdash/> that is,
                  put data values on the edges in the bar to the right <mdash/> we get the
                  figure
                </p>
                <p>
                  <em>[Figure showing scores histogram with binwidth 10 would go here]</em>
                </p>
              </statement>
            </example>

            <p>
              Actually, there is no reason that the bars always have to be ten units wide:
              it is important that they are all the same size and that how they handle the
              edge cases (whether the left or right bar gets a data value on edge), but
              they could be any size. We call the successive ranges of the <m>x</m> coordinates
              which get put together for each bar
              <term>bins</term> or
              <term>classes</term>, and it is up to the statistician
              to chose whichever bins <mdash/> where they start and how wide they are <mdash/> shows the
              data best.
            </p>

            <p>
              Typically, the smaller the bin size, the more variation (precision) can be
              seen in the bars <ellipsis/> but sometimes there is so much variation that the result
              seems to have a lot of random jumps up and down, like static on the radio.
              On the other hand, using a large bin size makes the picture smoother <ellipsis/> but
              sometimes, it is so smooth that very little information is left. Some of this
              is shown in the following
            </p>

            <example xml:id="eg-scoreshistvariousbins">
              <idx>histogram</idx>
              <statement>
                <p>
                  Continuing with the score data in Example <xref ref="eg-stemandleafplot"/> and now
                  using the bins
                  with <m>x</m> satisfying <m>10\le x&lt;12</m>, then <m>12\le x&lt;14</m>, <em>etc.</em>,
                  we get the histogram with bins of width 2:
                </p>
                <p>
                  <em>[Figure showing scores histogram with binwidth 2 would go here]</em>
                </p>

                <p>
                  If we use the bins with <m>x</m> satisfying <m>10\le x&lt;15</m>, then <m>15\le x&lt;20</m>,
                  <em>etc.</em>, we get the histogram with bins of width 5:
                </p>
                <p>
                  <em>[Figure showing scores histogram with binwidth 5 would go here]</em>
                </p>

                <p>
                  If we use the bins with <m>x</m> satisfying <m>20\le x&lt;40</m>, then <m>40\le x&lt;60</m>,
                  <em>etc.</em>, we get the histogram with bins of width 20:
                </p>
                <p>
                  <em>[Figure showing scores histogram with binwidth 20 would go here]</em>
                </p>

                <p>
                  Finally, if we use the bins with <m>x</m> satisfying <m>0\le x&lt;50</m>, then
                  <m>50\le x&lt;100</m>, and then <m>100\le x&lt;150</m>, we get the histogram with bins of
                  width 50:
                </p>
                <p>
                  <em>[Figure showing scores histogram with binwidth 50 would go here]</em>
                </p>
              </statement>
            </example>
          </subsection>
          <subsection xml:id="ssec-RFHistograms">
            <title>[Relative Frequency] Histograms</title>
            <idx><h>histogram</h><h>relative frequency</h></idx>
            <p>
              Just as we could have bar charts with absolute (<xref ref="ssec-BCIFC"/>) or
              relative (<xref ref="ssec-BCIIRFC"/>) frequencies, we can do the same for
              histograms. Above, in
              <xref ref="ssec-FHistograms"/>, we made absolute frequency histograms. If, instead,
              we divide each of the counts used to determine the heights of the bars by the
              total sample size, we will get fractions or percents <mdash/> <em>relative</em>
              frequencies. We should then change the label on the <m>y</m>-axis and the
              tick-marks numbers on the <m>y</m>-axis, but otherwise the graph will look exactly
              the same (as it did with relative frequency bar charts compared with absolute
              frequency bar chars).
            </p>

            <example xml:id="eg-scoresRFhistbytens">
              <idx><h>histogram</h><h>relative frequency</h></idx>
              <statement>
                <p>
                  Let's make the relative frequency histogram corresponding to the absolute
                  frequency histogram in Example <xref ref="eg-scoreshistbytens"/>, based on the data
                  from Example <xref ref="eg-stemandleafplot"/> <mdash/> all we have to do is change the
                  numbers used to make heights of the bars in the graph by dividing them by
                  the sample size, 30, and then also change the <m>y</m>-axis label and tick mark
                  numbers.
                </p>
                <p>
                  <em>[Figure showing scores relative frequency histogram with binwidth 10 would go here]</em>
                </p>
              </statement>
            </example>
          </subsection>
          <subsection xml:id="ssec-HtTAH">
            <title>How to Talk About Histograms</title>
            <idx>distribution</idx>
            <idx><h>shape</h><h>histogram</h></idx>
            <idx>center of a histogram, dataset, or distribution</idx>
            <idx>spread of a histogram, dataset, or distribution</idx>
            <idx>symmetric histogram, dataset, or distribution</idx>
            <idx>skewed histogram, dataset, or distribution</idx>
            <idx>unimodal histogram, dataset, or distribution</idx>
            <idx>multimodal histogram, dataset, or distribution</idx>
            <p>
              Histograms of course tell us what the data values are <mdash/> the location along
              the <m>x</m> value of a bar is the value of the variable <mdash/> and how many of them
              have each particular value <mdash/> the height of the bar tells how many data values
              are in that bin. This is also given a technical name
            </p>

            <definition xml:id="def-distribution">
              <idx>distribution</idx>
              <statement>
                <p>
                  Given a variable defined on a population, or at least on a sample, the
                  <term>distribution</term> of that variable is a list of all the values the variable
                  actually takes on and how many times it takes on these values.
                </p>
              </statement>
            </definition>

            <p>
              The reason we like the visual version of a distribution, its histogram, is
              that our visual intuition can then help us answer general, qualitative
              questions about what those data must be telling us. The first questions we
              usually want to answer quickly about the data are
            </p>
            <ul>
              <li>
                <p>
                  What is the <em>shape</em> of the histogram?
                </p>
              </li>
              <li>
                <p>
                  Where is its <em>center</em>?
                </p>
              </li>
              <li>
                <p>
                  How much <em>variability</em> [also called
                  <em>spread</em>] does it show?
                </p>
              </li>
            </ul>

            <p>
              When we talk about the general shape of a histogram, we often use the terms
            </p>

            <definition xml:id="def-symmskew">
              <idx>symmetric histogram, dataset, or distribution</idx>
              <idx>skewed histogram, dataset, or distribution</idx>
              <idx>unimodal histogram, dataset, or distribution</idx>
              <idx>multimodal histogram, dataset, or distribution</idx>
              <statement>
                <p>
                  A histogram is <term>symmetric</term> if the left half is (approximately) the mirror
                  image of the right half.
                </p>

                <p>
                  We say a histogram is <term>skewed left</term> if the tail on the left side is longer
                  than on the right. In other words, left skew is when the left half of the
                  histogram <mdash/> half in the sense that the total of the bars in this left part
                  is half of the size of the dataset <mdash/> extends farther to the left than the
                  right does to the right. Conversely, the histogram is <term>skewed right</term> if
                  the right half extends farther to the right than the left does to the left.
                </p>

                <p>
                  If the shape of the histogram has one significant peak, then we say it is
                  <term>unimodal</term>, while if it has several such, we say it is <term>multimodal</term>.
                </p>
              </statement>
            </definition>

            <p>
              It is often easy to point to where the center of a distribution <em>looks
              like</em> it lies, but it is hard to be precise. It is particularly difficult
              if the histogram is <q>noisy,</q> maybe multimodal. Similarly, looking at a
              histogram, it is often easy to say it is <q>quite spread out</q> or <q>very
              concentrated in the center,</q> but it is then hard to go beyond this general
              sense.
            </p>

            <p>
              Precision in our discussion of the center and spread of a dataset will
              only be possible in the next section, when we work with numerical measures
              of these features.
            </p>
          </subsection>
        </section>
        <section xml:id="sec-NDoDIMotC">
          <title>Numerical Descriptions of Data, I: Measures of the Center</title>
          <p>
            Oddly enough, there are several measures of central tendency, as ways to
            define the middle of a dataset are called.  There is different work to be
            done to calculate each of them, and they have different uses, strengths, and
            weaknesses.
          </p>

          <p>
            For this whole section we will assume we have collected <m>n</m> numerical values,
            the values of our quantitative
            variable<idx>quantitative variable</idx><idx>variable!quantitative</idx> for the
            sample we were able to study.  When we write formul√¶ with these values,
            we can't give them variable names that look like <m>a, b, c, \dots</m>, because we
            don't know where to stop (and what would we do if <m>n</m> were more than 26?).
            Instead, we'll use the variables <m>x_1, x_2, \dots, x_n</m> to represent the data
            values.
          </p>

          <p>
            One more very convenient bit of notation, once we have started writing an
            unknown number (<m>n</m>) of numbers <m>x_1, x_2, \dots, x_n</m>, is a way of writing
            their sum:
          </p>

          <definition xml:id="def-summation">
            <idx>summation notation, <m>\Sigma</m></idx>
            <idx><m>\Sigma</m>, summation notation</idx>
            <idx>pig, yellow</idx>
            <statement>
              <p>
                If we have <m>n</m> numbers which we write <m>x_1, \dots, x_n</m>, then we use the
                shorthand <term>summation notation</term> <m>\sum x_i</m> to represent the sum
                <m>\sum x_i = x_1 + \dots + x_n</m>.  <fn>Sometimes you will see this written
                instead <m>\sum_{i=1}^n x_i</m>.  Think of the <q><m>\sum_{i=1}^n{}</m></q>
                as a little computer program which with <m>i=1</m>, increases it one step at a time
                until it gets all the way to <m>i=n</m>, and adds up whatever is to the right.  So,
                for example, <m>\sum_{i=1}^3 2i</m> would be <m>(2*1)+(2*2)+(2*3)</m>, and so has the value <m>12</m>.</fn>
              </p>
            </statement>
          </definition>

          <example xml:id="eg-subscriptssums">
            <statement>
              <p>
                If our dataset were <m>\{1, 2, 17, -3.1415, 3/4\}</m>, then <m>n</m> would be 5 and the
                variables <m>x_1, \dots, x_5</m> would be defined with values <m>x_1=1</m>, <m>x_2=2</m>,
                <m>x_3=17</m>, <m>x_4=-3.1415</m>, and <m>x_5=3/4</m>.
              </p>

              <p>
                In addition<fn>no pun intended</fn>, we would have <m>\sum x_i = x_1+x_2+x_3+x_4+x_5=1+2+17-3.1415+ 3/4=17.6085</m>.
              </p>
            </statement>
          </example>

          <subsection xml:id="ssec-Mode">
            <title>Mode</title>
            <p>
              Let's first discuss probably the simplest measure of central tendency, and in
              fact one which was foreshadowed by terms like <q>unimodal.</q>
            </p>

            <definition xml:id="def-mode">
              <idx>mode</idx>
              <statement>
                <p>
                  A <term>mode</term> of a dataset <m>x_1, \dots, x_n</m> of <m>n</m> numbers is one of the
                  values <m>x_i</m> which occurs at least as often in the dataset as any other value.
                </p>
              </statement>
            </definition>

            <p>
              It would be nice to say this in a simpler way, something like <q>the mode is
              the value which occurs the most often in the dataset,</q> but there may not be
              a single such number.
            </p>

            <example xml:id="eg-mode">
              <statement>
                <p>
                  Continuing with the data from <xref ref="eg-stemandleafplot"/>, it is easy to
                  see, looking at the stem-and-leaf plot, that both 73 and 90 are modes.
                </p>

                <p>
                  Note that in some of the histograms we made using these data and different bin
                  widths, the bins containing 73 and 90 were of the same height, while in others
                  they were of different heights.  This is an example of how it can be quite hard
                  to see on a histogram where the mode is... or where the mode<term>s are</term>.
                </p>
              </statement>
            </example>
          </subsection>

          <subsection xml:id="ssec-Mean">
            <title>Mean</title>
            <p>
              The next measure of central tendency, and certainly the one heard most often
              in the press, is simply the average.  However, in statistics, this is given a
              different name.
            </p>

            <definition xml:id="def-mean">
              <idx>mean</idx>
              <idx>average!see: {mean}</idx>
              <statement>
                <p>
                  The <term>mean</term> of a dataset <m>x_1, \dots, x_n</m> of <m>n</m> numbers is given by the
                  formula <m>\left(\sum x_i\right)/n</m>.
                </p>

                <p>
                  If the data come from a sample, we use the notation
                  <m>\overline{x}</m><idx><m>\overline{x}</m>, sample mean</idx> for the 
                  <term>sample mean</term><idx>sample mean, <m>\overline{x}</m></idx><idx>mean!sample</idx>.
                </p>

                <p>
                  If <m>\{x_1, \dots, x_n\}</m> is all of the data from an entire population, we use
                  the notation <m>\mu_X</m> [this is the Greek letter <q>mu,</q> pronounced <q>mew,</q> to
                  rhyme with <q>new.</q>] for the
                  <term>population mean</term><idx>population mean, <m>\mu_X</m></idx><idx>mean!population</idx><idx><m>\mu_X</m>, population mean</idx>.
                </p>
              </statement>
            </definition>

            <example xml:id="eg-mean1">
              <statement>
                <p>
                  Since we've already computed the sum of the data in
                  <xref ref="eg-subscriptssums"/> to be <m>17.6085</m> and there were <m>5</m> values in
                  the dataset, the mean is <m>\overline{x}=17.6085/5 = 3.5217</m><idx>sample mean, <m>\overline{x}</m></idx><idx>mean!sample</idx><idx><m>\overline{x}</m>, sample mean</idx>.
                </p>
              </statement>
            </example>

            <example xml:id="eg-mean2">
              <statement>
                <p>
                  Again using the data from <xref ref="eg-stemandleafplot"/>, we can calculate
                  the mean <m>\overline{x}=\left(\sum x_i\right)/n =2246/30=74.8667</m><idx>sample mean, <m>\overline{x}</m></idx><idx>mean!sample</idx><idx><m>\overline{x}</m>, sample mean</idx>.
                </p>
              </statement>
            </example>

            <p>
              Notice that the mean in the two examples above was not one of the data values.
              This is true quite often.  What that means is that the phrase <q>the average
              <em>whatever</em>,</q> as in <q>the average American family has <m>X</m></q> or <q>the
              average student does <m>Y</m>,</q> is not talking about any particular family, and
              we should not expect any particular family or student to have or do that
              thing.  Someone with a statistical education should mentally edit every
              phrase like that they hear to be instead something like <q>the mean of the
              variable <m>X</m> on the population of all American families is ...,</q> or <q>the
              mean of the variable <m>Y</m> on the population of all students is ...,</q> or
              whatever.
            </p>
          </subsection>

          <subsection xml:id="ssec-Median">
            <title>Median</title>
            <p>
              Our third measure of central tendency is not the result of arithmetic, but
              instead of putting the data values in increasing order.
            </p>

            <definition xml:id="def-median">
              <idx>median</idx>
              <statement>
                <p>
                  Imagine that we have put the values of a dataset <m>\{x_1, \dots, x_n\}</m> of <m>n</m>
                  numbers in increasing (or at least non-decreasing) order, so that
                  <m>x_1\le x_2\le \dots \le x_n</m>.  Then if <m>n</m> is odd, the <term>median</term> of
                  the dataset is the middle value, <m>x_{(n+1)/2}</m>, while if <m>n</m> is even,
                  the median is the mean  of the two middle numbers,
                  <m>\frac{x_{n/2}+x_{(n/2)+1}}{2}</m>.
                </p>
              </statement>
            </definition>

            <example xml:id="eg-median1">
              <statement>
                <p>
                  Working with the data in <xref ref="eg-subscriptssums"/>, we must first put
                  them in order, as <m>\{-3.1415, 3/4, 1, 2, 17\}</m>, so the median of this
                  dataset is the middle value, <m>1</m>.
                </p>
              </statement>
            </example>

            <example xml:id="eg-median2">
              <statement>
                <p>
                  Now let us find the median of the data from <xref ref="eg-stemandleafplot"/>.
                  Fortunately, in that example, we made a stem-and-leaf plot and even put the
                  leaves in order, so that starting at the bottom and going along the rows of
                  leaves and then up to the next row, will give us all the values in order!
                  Since there are 30 values, we count up to the <m>15^{th}</m> and <m>16^{th}</m> values,
                  being 76 and 77, and from this we find that the median of the dataset is
                  <m>\frac{76+77}{2}=76.5</m>.
                </p>
              </statement>
            </example>
          </subsection>

          <subsection xml:id="ssec-SaWoTMoCT">
            <title>Strengths and Weaknesses of These Measures of Central Tendency</title>
            <p>
              The weakest of the three measures above is the mode<idx>mode</idx>.  Yes, it is
              nice to know which value happened most often in a dataset (or which values all
              happened equally often and more often then all other values).  But this often
              does not necessarily tell us much about the over-all structure of the data.
            </p>

            <example xml:id="eg-modeweak">
              <idx>mode</idx>
              <statement>
                <p>
                  Suppose we had the data
                  <me>
                    \begin{matrix}
                    86 &amp; 80 &amp; 25 &amp; 77 &amp; 73 &amp; 76 &amp; 100 &amp; 90 &amp; 67 &amp; 93\\
                    94 &amp; 83 &amp; 72 &amp; 75 &amp; 79 &amp; 70 &amp; 91 &amp; 82 &amp; 71 &amp; 95\\
                    40 &amp; 58 &amp; 68 &amp; 69 &amp; 100 &amp; 78 &amp; 87 &amp; 25 &amp; 92 &amp; 74
                    \end{matrix}
                  </me>
                  with corresponding stem-and-leaf plot
                </p>

                <p>
                  [PLACEHOLDER: Table with stem-and-leaf plot showing stems 2-10 with leaves]
                </p>

                <p>
                  This would have a histogram with bins of width 10 that looks exactly like the
                  one in <xref ref="eg-scoreshistbytens"/> <mdash/> so the center of the histogram
                  would seem, visually, still to be around the bar over the 80s <mdash/> but now
                  there is a unique mode of 25.
                </p>
              </statement>
            </example>

            <p>
              What this example shows is that a small change in some of the data values,
              small enough not to change the histogram at all, can change the mode(s)
              drastically.  It also shows that the location of the mode says very little
              about the data in general or its shape, the mode is based entirely on a 
              possibly accidental coincidence of some values in the dataset, no matter if
              those values are in the <q>center</q> of the histogram or not.
            </p>

            <p>
              The mean<idx>mean</idx> has a similar problem: a small change in the data, in the
              sense of adding only one new data value, but one which is very far away from
              the others, can change the mean quite a bit.  Here is an example.
            </p>

            <example xml:id="eg-mean3">
              <statement>
                <p>
                  Suppose we take the data from <xref ref="eg-stemandleafplot"/> but change only
                  one value <mdash/> such as by changing the 100 to a 1000, perhaps by a simple typo
                  of the data entry.  Then if we calculate the mean, we get
                  <m>\overline{x}=\left(\sum x_i\right)/n =3146/30=104.8667</m><idx>sample mean, <m>\overline{x}</m></idx><idx>mean!sample</idx><idx><m>\overline{x}</m>, sample mean</idx>, which is quite
                  different from the mean of original dataset.
                </p>
              </statement>
            </example>

            <p>
              A data value which seems to be quite different from all (or the great majority
              of) the rest is called an <em>outlier</em><idx>outlier</idx><fn>This is a very
              informal definition of an outlier.  Below we will have an extremely precise
              one.</fn>  What we have just seen is that
              <term>the mean is very sensitive to outliers</term><idx>sensitive to outliers</idx>.
              This is a serious defect, although otherwise it is easy to compute, to work
              with, and to prove theorems about.
            </p>

            <p>
              Finally, the median<idx>median</idx> is somewhat tedious to compute, because
              the first step is to put all the data values in order, which can be very
              time-consuming.  But, once that is done, throwing in an outlier tends to move
              the median only a little bit.  Here is an example.
            </p>

            <example xml:id="eg-median3">
              <statement>
                <p>
                  If we do as in <xref ref="eg-mean3"/> and change the data value of 100 in the
                  dataset of <xref ref="eg-stemandleafplot"/> to 1000, but leave all of the other
                  data values unchanged, it does not change the median at all since the 1000 is
                  the new largest value, and that does not change the two middle values at all.
                </p>

                <p>
                  If instead we take the data of <xref ref="eg-stemandleafplot"/> and simply add
                  another value, 1000, without taking away the 100, that does change the media:
                  there are now an odd number of data values, so the median is the middle one
                  after they are put in order, which is 78.  So the median has changed by only
                  half a point, from 77.5 to 78.   And his would even be true if the value we
                  were adding to the dataset were 1000000 and not just 1000!
                </p>
              </statement>
            </example>

            <p>
              In other words,
              <term>the median is very insensitive to outliers</term><idx>insensitive to outliers</idx>.
              Since, in practice, it is very easy for datasets to have a few random, bad
              values (typos, mechanical errors, <em>etc.</em>), which are often outliers, it
              is usually smarter to use the median than the mean.
            </p>

            <p>
              As one final point, note that as we mentioned in <xref ref="ssec-Mean"/>, the
              word <q>average,</q> the unsophisticated version of <q>mean,</q> is often incorrectly
              used as a modifier of the individuals in some population being studied (as in
              <q>the average American ...</q>), rather than as a modifier of the variable in
              the study (<q>the average income...</q>), indicating a fundamental misunderstanding
              of what the mean <em>means</em>.  If you look a little harder at this
              misunderstanding, though, perhaps it is based on the idea that we are looking
              for the center, the <q>typical</q> value of the variable.
            </p>

            <p>
              The mode might seem like a good way <mdash/> it's the most frequently occurring
              value.  But we have seen how that is somewhat flawed.
            </p>

            <p>
              The mean might also seem like a good way <mdash/> it's the <q>average,</q> literally.
              But we've also seen problems with the mean.
            </p>

            <p>
              In fact, the median is probably closest to the intuitive idea of <q>the center
              of the data.</q>  It is, after all, a value with the property that both above
              and below that value lie half of the data values.
            </p>

            <p>
              One last example to underline this idea:
            </p>

            <example xml:id="eg-meanmedianincome">
              <idx>mean</idx>
              <idx>median</idx>
              <idx>income distribution</idx>
              <idx>Great Recession</idx>
              <statement>
                <p>
                  The period of economic difficulty for world markets in the late 2000s and early
                  2010s is sometimes called the <term>Great Recession</term>.  Suppose a politician says
                  that we have come out of that time of troubles, and gives as proof the fact
                  that the average family income has increased from the low value it had during
                  the Great Recession back to the values it had before then, and perhaps is even
                  higher than it was in 2005.
                </p>

                <p>
                  It is possible that in fact people are better off, as the increase in this
                  average <mdash/> mean <mdash/> seems to imply.  But it is also possible that while the mean
                  income has gone up, the <em>median</em> income is still low.  This would happen
                  if the histogram of incomes recently still has most of the tall bars down
                  where the variable (family income) is low, but has a few, very high outliers.
                  In short, if the super-rich have gotten even super-richer, that will make the
                  mean (average) go up, even if most of the population has experienced stagnant
                  or decreasing wages <mdash/> but the median will tell what is happening to most of
                  the population.
                </p>

                <p>
                  So when a politician uses the evidence of the average (mean) as suggested here,
                  it is possible they are trying to hide from the pubic the reality of what is
                  happening to the rich and the not-so-rich.  It is also possible that this
                  politician is simply poorly educated in statistics and doesn't realize what is
                  going on.  You be the judge ... but pay attention so you know what to ask about.
                </p>
              </statement>
            </example>

            <p>
              The last thing we need to say about the strengths and weaknesses of our
              different measures of central tendency is a way to use the weaknesses of the
              mean and median to our advantage.  That is, since the mean is sensitive to
              outliers<idx>sensitive to outliers</idx>, and pulled in the direction of those outliers, while the median is
              not, we can use the difference between the two to tell us which way a histogram
              is skewed.
            </p>

            <p>
              <term>Fact:</term> If the mean of a dataset is larger than the median, then histograms of that
              dataset will be right-skewed<idx>right-skewed histogram, dataset, or distribution</idx><idx>skewed histogram, dataset, or distribution!right</idx>.  Similarly, if the mean is less than the median,
              histograms will be left-skewed<idx>left-skewed histogram, dataset, or distribution</idx><idx>skewed histogram, dataset, or distribution!left</idx>.
              <idx>mean</idx><idx>median</idx><idx>skewed histogram, dataset, or distribution</idx>
            </p>
          </subsection>
        </section>
        <section xml:id="sec-NDoDIMoS">
          <title>Numerical Descriptions of Data, II: Measures of Spread</title>
          <p/>
          <subsection xml:id="ssec-Range">
            <title>Range</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-QuartilesIQR">
            <title>Quartiles and the IQR</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-VarStdDev">
            <title>Variance and Standard Deviation</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-SaWoTMoS">
            <title>Strengths and Weaknesses of These Measures of Spread</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-AFDoO">
            <title>A Formal Definition of Outliers -- the 1.5 IQR Rule</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-TF-NSaB">
            <title>The Five-Number Summary and Boxplots</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-one-variable-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>

      <chapter xml:id="chap-bivariate-basics">
        <title>Bi-variate Statistics: Basics</title>
        <section xml:id="sec-TERoID">
          <title>Terminology: Explanatory/Response or Independent/Dependent</title>
          <p/>
        </section>
        <section xml:id="sec-scatterplots">
          <title>Scatterplots</title>
          <p/>
        </section>
        <section xml:id="sec-correlation">
          <title>Correlation</title>
          <p/>
        </section>
        <section xml:id="sec-bivariate-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>

      <chapter xml:id="chap-linear-regression">
        <title>Linear Regression</title>
        <section xml:id="sec-TLSRL">
          <title>The Least Squares Regression Line</title>
          <p/>
        </section>
        <section xml:id="sec-AaIoLSRLs">
          <title>Applications and Interpretations of LSRLs</title>
          <p/>
        </section>
        <section xml:id="sec-Cs">
          <title>Cautions</title>
          <p/>
          <subsection xml:id="ssec-S2O">
            <title>Sensitivity to Outliers</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-causation">
            <title>Causation</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-extrapolation">
            <title>Extrapolation</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-SP">
            <title>Simpson's Paradox</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-linear-regression-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>
    </part>

    <part xml:id="part-GD">
      <title>Good Data</title>

      <chapter xml:id="chap-probability-theory">
        <title>Probability Theory</title>
        <section xml:id="sec-defsforprob">
          <title>Definitions for Probability</title>
          <p/>
          <subsection xml:id="ssec-SSSOaPMs">
            <title>Sample Spaces, Set Operations, and Probability Models</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-VDs">
            <title>Venn Diagrams</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-FPMs">
            <title>Finite Probability Models</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-condprob">
          <title>Conditional Probability</title>
          <p/>
        </section>
        <section xml:id="sec-RVs">
          <title>Random Variables</title>
          <p/>
          <subsection xml:id="ssec-DoRVsaFEs">
            <title>Definition and First Examples</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-D4DRVs">
            <title>Distributions for Discrete RVs</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-expectation4DRVs">
            <title>Expectation for Discrete RVs</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-DF4CRVs">
            <title>Density Functions for Continuous RVs</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-TND">
            <title>The Normal Distribution</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-probability-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>

      <chapter xml:id="chap-bringing-home-data">
        <title>Bringing Home the Data</title>
        <section xml:id="sec-SoaSPC">
          <title>Studies of a Population Parameter</title>
          <p/>
        </section>
        <section xml:id="sec-SoC">
          <title>Studies of Causality</title>
          <p/>
          <subsection xml:id="ssec-CGs">
            <title>Control Groups</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-human-subject-experiments-placebo-effect">
            <title>Human-Subject Experiments: The Placebo Effect</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-blinding">
            <title>Blinding</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-CiaRCTs">
            <title>Combining it all: RCTs</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-CLVs">
            <title>Confounded Lurking Variables</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-EE">
          <title>Experimental Ethics</title>
          <p/>
          <subsection xml:id="ssec-DNH">
            <title>"Do No Harm"</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-IC">
            <title>Informed Consent</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-Confidentiality">
            <title>Confidentiality</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-EOIRB">
            <title>External Oversight [IRB]</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-bringing-home-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>
    </part>

    <part xml:id="part-IS">
      <title>Inferential Statistics</title>

      <chapter xml:id="chap-IS">
        <title>Basic Inferences</title>
        <section xml:id="sec-CLT">
          <title>The Central Limit Theorem</title>
          <p/>
        </section>
        <section xml:id="sec-BCIs">
          <title>Basic Confidence Intervals</title>
          <p/>
          <subsection xml:id="ssec-CIcautions">
            <title>Cautions</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-BHT">
          <title>Basic Hypothesis Testing</title>
          <p/>
          <subsection xml:id="ssec-tFSoHT">
            <title>The Formal Steps of Hypothesis Testing</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-HSiSEfpvs">
            <title>How Small is Small Enough, for p-values?</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-calculations-hypothesis-testing-population-means">
            <title>Calculations for Hypothesis Testing of Population Means</title>
            <p/>
          </subsection>
          <subsection xml:id="ssec-HTcautions">
            <title>Cautions</title>
            <p/>
          </subsection>
        </section>
        <section xml:id="sec-basic-inferences-exercises">
          <title>Exercises</title>
          <p/>
        </section>
      </chapter>
    </part>
  </book>
</pretext>
