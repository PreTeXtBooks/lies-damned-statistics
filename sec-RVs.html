<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Random Variables</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Lies, Damned Lies, or Statistics">
<script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math"
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "https://pretextbook.org/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="https://pretextbook.org/js/0.3/pretext_search.js"></script><link href="https://pretextbook.org/css/0.7/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.3</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.3/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.3/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.3/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link href="https://pretextbook.org/css/0.7/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/setcolors.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ldlos.html"><span class="title">Lies, Damned Lies, or Statistics:</span> <span class="subtitle">How to Tell the Truth with Statistics</span></a></h1>
<p class="byline"></p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="avatarbutton" class="avatarbutton name">You!</span><div id="preferences_menu_holder" class="preferences_menu_holder hidden"><ol id="preferences_menu" class="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">‚úîÔ∏è</span>You!</li>
<li data-val="üò∫" tabindex="-1">
<span id="theüò∫" class="avatarcheck"></span>üò∫</li>
<li data-val="üë§" tabindex="-1">
<span id="theüë§" class="avatarcheck"></span>üë§</li>
<li data-val="üëΩ" tabindex="-1">
<span id="theüëΩ" class="avatarcheck"></span>üëΩ</li>
<li data-val="üê∂" tabindex="-1">
<span id="theüê∂" class="avatarcheck"></span>üê∂</li>
<li data-val="üêº" tabindex="-1">
<span id="theüêº" class="avatarcheck"></span>üêº</li>
<li data-val="üåà" tabindex="-1">
<span id="theüåà" class="avatarcheck"></span>üåà</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">‚úîÔ∏è</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller‚ÄÖgap‚ÄÉ</li>
<li data-val="wspace" data-change="1" tabindex="-1">larger‚ÄÉgap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">‚úîÔ∏è</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">‚úîÔ∏è</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">‚úîÔ∏è</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button><span class="treebuttons"><a class="previous-button button" href="sec-condprob.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="chap-probability-theory.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="sec-probability-exercises.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth3 parts"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter-1.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="release-notes.html" class="internal"><span class="title">Release Notes</span></a></div></li>
<li><div class="toc-item"><a href="preface.html" class="internal"><span class="title">Preface</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="part-DS.html" class="internal"><span class="codenumber">I</span> <span class="title">Descriptive Statistics</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="chap-1VS.html" class="internal"><span class="codenumber">1</span> <span class="title">One-Variable Statistics: Basics</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-TIPVS.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Terminology: Individuals/Population/Variables/Samples</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-VRoDICV.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Visual Representation of Data, I: Categorical Variables</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-VRoDICV.html#ssec-BCIFC" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Bar Charts I: Frequency Charts</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDICV.html#ssec-BCIIRFC" class="internal"><span class="codenumber">1.2.2</span> <span class="title">Bar Charts II: Relative Frequency Charts</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDICV.html#ssec-BCIIIC" class="internal"><span class="codenumber">1.2.3</span> <span class="title">Bar Charts III: Cautions</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDICV.html#ssec-PC" class="internal"><span class="codenumber">1.2.4</span> <span class="title">Pie Charts</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-VRoDIIQV.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Visual Representation of Data, II: Quantitative Variables</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-VRoDIIQV.html#ssec-SalP" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Stem-and-leaf Plots</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDIIQV.html#ssec-FHistograms" class="internal"><span class="codenumber">1.3.2</span> <span class="title">[Frequency] Histograms</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDIIQV.html#ssec-RFHistograms" class="internal"><span class="codenumber">1.3.3</span> <span class="title">[Relative Frequency] Histograms</span></a></div></li>
<li><div class="toc-item"><a href="sec-VRoDIIQV.html#ssec-HtTAH" class="internal"><span class="codenumber">1.3.4</span> <span class="title">How to Talk About Histograms</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-NDoDIMotC.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Numerical Descriptions of Data, I: Measures of the Center</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-NDoDIMotC.html#ssec-Mode" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Mode</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMotC.html#ssec-Mean" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Mean</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMotC.html#ssec-Median" class="internal"><span class="codenumber">1.4.3</span> <span class="title">Median</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMotC.html#ssec-SaWoTMoCT" class="internal"><span class="codenumber">1.4.4</span> <span class="title">Strengths and Weaknesses of These Measures of Central Tendency</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-NDoDIMoS.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Numerical Descriptions of Data, II: Measures of Spread</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-Range" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Range</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-QuartilesIQR" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Quartiles and the <span class="process-math">\(IQR\)</span></span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-VarStdDev" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Variance and Standard Deviation</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-SaWoTMoS" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Strengths and Weaknesses of These Measures of Spread</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-AFDoO" class="internal"><span class="codenumber">1.5.5</span> <span class="title">A Formal Definition of Outliers‚Äîthe <span class="process-math">\(1.5\,IQR\)</span> Rule</span></a></div></li>
<li><div class="toc-item"><a href="sec-NDoDIMoS.html#ssec-TF-NSaB" class="internal"><span class="codenumber">1.5.6</span> <span class="title">The Five-Number Summary and Boxplots</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-one-variable-exercises.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap-bivariate-basics.html" class="internal"><span class="codenumber">2</span> <span class="title">Bi-variate Statistics: Basics</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-TERoID.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Terminology: Explanatory/Response or Independent/Dependent</span></a></div></li>
<li><div class="toc-item"><a href="sec-scatterplots.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Scatterplots</span></a></div></li>
<li><div class="toc-item"><a href="sec-correlation.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Correlation</span></a></div></li>
<li><div class="toc-item"><a href="sec-bivariate-exercises.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap-linear-regression.html" class="internal"><span class="codenumber">3</span> <span class="title">Linear Regression</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-TLSRL.html" class="internal"><span class="codenumber">3.1</span> <span class="title">The Least Squares Regression Line</span></a></div></li>
<li><div class="toc-item"><a href="sec-AaIoLSRLs.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Applications and Interpretations of LSRLs</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-Cs.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Cautions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-Cs.html#ssec-S2O" class="internal"><span class="codenumber">3.3.1</span> <span class="title">Sensitivity to Outliers</span></a></div></li>
<li><div class="toc-item"><a href="sec-Cs.html#ssec-causation" class="internal"><span class="codenumber">3.3.2</span> <span class="title">Causation</span></a></div></li>
<li><div class="toc-item"><a href="sec-Cs.html#ssec-extrapolation" class="internal"><span class="codenumber">3.3.3</span> <span class="title">Extrapolation</span></a></div></li>
<li><div class="toc-item"><a href="sec-Cs.html#ssec-SP" class="internal"><span class="codenumber">3.3.4</span> <span class="title">Simpson‚Äôs Paradox</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-linear-regression-exercises.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="part-GD.html" class="internal"><span class="codenumber">II</span> <span class="title">Good Data</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="chap-probability-theory.html" class="internal"><span class="codenumber">4</span> <span class="title">Probability Theory</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-defsforprob.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Definitions for Probability</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-defsforprob.html#ssec-SSSOaPMs" class="internal"><span class="codenumber">4.1.1</span> <span class="title">Sample Spaces, Set Operations, and Probability Models</span></a></div></li>
<li><div class="toc-item"><a href="sec-defsforprob.html#ssec-VDs" class="internal"><span class="codenumber">4.1.2</span> <span class="title">Venn Diagrams</span></a></div></li>
<li><div class="toc-item"><a href="sec-defsforprob.html#ssec-FPMs" class="internal"><span class="codenumber">4.1.3</span> <span class="title">Finite Probability Models</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-condprob.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Conditional Probability</span></a></div></li>
<li class="active">
<div class="toc-item"><a href="sec-RVs.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Random Variables</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-RVs.html#ssec-DoRVsaFEs" class="internal"><span class="codenumber">4.3.1</span> <span class="title">Definition and First Examples</span></a></div></li>
<li><div class="toc-item"><a href="sec-RVs.html#ssec-D4DRVs" class="internal"><span class="codenumber">4.3.2</span> <span class="title">Distributions for Discrete RVs</span></a></div></li>
<li><div class="toc-item"><a href="sec-RVs.html#ssec-expectation4DRVs" class="internal"><span class="codenumber">4.3.3</span> <span class="title">Expectation for Discrete RVs</span></a></div></li>
<li><div class="toc-item"><a href="sec-RVs.html#ssec-DF4CRVs" class="internal"><span class="codenumber">4.3.4</span> <span class="title">Density Functions for Continuous RVs</span></a></div></li>
<li><div class="toc-item"><a href="sec-RVs.html#ssec-TND" class="internal"><span class="codenumber">4.3.5</span> <span class="title">The Normal Distribution</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-probability-exercises.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap-bringing-home-data.html" class="internal"><span class="codenumber">5</span> <span class="title">Bringing Home the Data</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-SoaSPC.html" class="internal"><span class="codenumber">5.1</span> <span class="title">Studies of a Population Parameter</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-SoC.html" class="internal"><span class="codenumber">5.2</span> <span class="title">Studies of Causality</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-SoC.html#ssec-CGs" class="internal"><span class="codenumber">5.2.1</span> <span class="title">Control Groups</span></a></div></li>
<li><div class="toc-item"><a href="sec-SoC.html#ssec-human-subject-experiments-placebo-effect" class="internal"><span class="codenumber">5.2.2</span> <span class="title">Human-Subject Experiments: The Placebo Effect</span></a></div></li>
<li><div class="toc-item"><a href="sec-SoC.html#ssec-blinding" class="internal"><span class="codenumber">5.2.3</span> <span class="title">Blinding</span></a></div></li>
<li><div class="toc-item"><a href="sec-SoC.html#ssec-CiaRCTs" class="internal"><span class="codenumber">5.2.4</span> <span class="title">Combining it all: RCTs</span></a></div></li>
<li><div class="toc-item"><a href="sec-SoC.html#ssec-CLVs" class="internal"><span class="codenumber">5.2.5</span> <span class="title">Confounded Lurking Variables</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-EE.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Experimental Ethics</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-EE.html#ssec-DNH" class="internal"><span class="codenumber">5.3.1</span> <span class="title">"Do No Harm"</span></a></div></li>
<li><div class="toc-item"><a href="sec-EE.html#ssec-IC" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Informed Consent</span></a></div></li>
<li><div class="toc-item"><a href="sec-EE.html#ssec-Confidentiality" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Confidentiality</span></a></div></li>
<li><div class="toc-item"><a href="sec-EE.html#ssec-EOIRB" class="internal"><span class="codenumber">5.3.4</span> <span class="title">External Oversight [IRB]</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-bringing-home-exercises.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="part-IS.html" class="internal"><span class="codenumber">III</span> <span class="title">Inferential Statistics</span></a></div>
<ul class="structural"><li>
<div class="toc-item"><a href="chap-IS.html" class="internal"><span class="codenumber">6</span> <span class="title">Basic Inferences</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-CLT.html" class="internal"><span class="codenumber">6.1</span> <span class="title">The Central Limit Theorem</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-BCIs.html" class="internal"><span class="codenumber">6.2</span> <span class="title">Basic Confidence Intervals</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-BCIs.html#ssec-CIcautions" class="internal"><span class="codenumber">6.2.1</span> <span class="title">Cautions</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-BHT.html" class="internal"><span class="codenumber">6.3</span> <span class="title">Basic Hypothesis Testing</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-BHT.html#ssec-tFSoHT" class="internal"><span class="codenumber">6.3.1</span> <span class="title">The Formal Steps of Hypothesis Testing</span></a></div></li>
<li><div class="toc-item"><a href="sec-BHT.html#ssec-HSiSEfpvs" class="internal"><span class="codenumber">6.3.2</span> <span class="title">How Small is Small Enough, for p-values?</span></a></div></li>
<li><div class="toc-item"><a href="sec-BHT.html#ssec-calculations-hypothesis-testing-population-means" class="internal"><span class="codenumber">6.3.3</span> <span class="title">Calculations for Hypothesis Testing of Population Means</span></a></div></li>
<li><div class="toc-item"><a href="sec-BHT.html#ssec-HTcautions" class="internal"><span class="codenumber">6.3.4</span> <span class="title">Cautions</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-basic-inferences-exercises.html" class="internal"><span class="codenumber">6.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li></ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-RVs"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.3</span> <span class="title">Random Variables</span>
</h2>
<section class="subsection" id="ssec-DoRVsaFEs"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.1</span> <span class="title">Definition and First Examples</span>
</h3>
<div class="para" id="p-447">Suppose we are doing a random experiment and there is some consequence of the result in which we are interested that can be measured by a number. The experiment might be playing a game of chance and the result could be how much you win or lose depending upon the outcome, or the experiment could be which part of the drivers‚Äô manual you randomly choose to study and the result how many points we get on the driver‚Äôs license test we make the next day, or the experiment might be giving a new drug to a random patient in medical study and the result would be some medical measurement you make after treatment (blood pressure, white blood cell count, whatever), <em class="emphasis">etc.</em> There is a name for this situation in mathematics</div>
<article class="definition definition-like" id="def-RV"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.1</span><span class="period">.</span>
</h4>
<div class="para" id="p-448">A choice of a number for each outcome of a random experiment is called a <dfn class="terminology">random variable</dfn> [<dfn class="terminology">RV</dfn>]. If the values an RV takes can be counted, because they are either finite or countably infinite in number, the RV is called <dfn class="terminology">discrete</dfn>; if, instead, the RV takes on all the values in an interval of real numbers, the RV is called <dfn class="terminology">continuous</dfn>.</div> <div class="para" id="p-449">We usually use capital letters to denote RVs and the corresponding lowercase letter to indicate a particular numerical value the RV might have, like <span class="process-math">\(X\)</span> and <span class="process-math">\(x\text{.}\)</span>
</div></article><article class="example example-like" id="eg-RV1"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-RV1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.2</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-RV1"><article class="example example-like"><div class="para" id="p-450">Suppose we play a silly game where you pay me $5 to play, then I flip a fair coin and I give you $10 if the coin comes up heads and $0 if it comes up tails. Then your net winnings, which would be +$5 or -$5 each time you play, are a random variable. Having only two possible values, this RV is certainly discrete.</div></article></div>
<article class="example example-like" id="eg-RV2"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-RV2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.3</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-RV2"><article class="example example-like"><div class="para" id="p-451">Weather phenomena vary so much, due to such small effects ‚Äî such as the famous butterfly flapping its wings in the Amazon rain forest causing a hurricane in North America ‚Äî that they appear to be a random phenomenon. Therefore, observing the temperature at some weather station is a continuous random variable whose value can be any real number in some range like <span class="process-math">\(-100\)</span> to <span class="process-math">\(100\)</span> (we‚Äôre doing <em class="emphasis">science</em>, so we use <span class="process-math">\({}^\circ C\)</span>).</div></article></div>
<article class="example example-like" id="eg-RV3"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-RV3"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.4</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-RV3"><article class="example example-like"><div class="para" id="p-452">Suppose we look at the ‚Äú<em class="emphasis">roll two fair dice independently</em>‚Äù experiment from Example <a href="" class="xref" data-knowl="./knowl/eg-condprob4.html" title="Example 4.2.6">Example¬†4.2.6</a> and Example <a href="" class="xref" data-knowl="./knowl/eg-finiteprobmod3.html" title="Example 4.1.19">Example¬†4.1.19</a>, which was based on the probability model in Example <a href="" class="xref" data-knowl="./knowl/eg-finiteprobmod3.html" title="Example 4.1.19">Example¬†4.1.19</a> and sample space in Example <a href="" class="xref" data-knowl="./knowl/eg-sampspace3.html" title="Example 4.1.4">Example¬†4.1.4</a>. Let us consider in this situation the random variable <span class="process-math">\(X\)</span> whose value for some pair of dice rolls is the sum of the two numbers showing on the dice. So, for example, <span class="process-math">\(X(11)=2\text{,}\)</span> <span class="process-math">\(X(12)=3\text{,}\)</span> <em class="emphasis">etc.</em>
</div> <div class="para logical" id="p-453">
<div class="para">In fact, let‚Äôs make a table of all the values of <span class="process-math">\(X\text{:}\)</span>
</div>
<div class="displaymath process-math" id="md-16">
\begin{align*}
X(11) &amp;= 2\\
X(21) = X(12) &amp;= 3\\
X(31) = X(22) = X(13) &amp;=4\\
X(41) = X(32) = X(23) = X(14) &amp;= 5\\
X(51) = X(42) = X(33) = X(24) = X(15) &amp;= 6\\
X(61) = X(52) = X(43) = X(34) = X(25) = X(16) &amp;= 7\\
X(62) = X(53) = X(44) = X(35) = X(26) &amp;= 8\\
X(63) = X(54) = X(45) = X(36) &amp;= 9\\
X(64) = X(55) = X(46) &amp;= 10\\
X(65) = X(56) &amp;= 11\\
X(66) &amp;= 12
\end{align*}
</div>
</div></article></div></section><section class="subsection" id="ssec-D4DRVs"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.2</span> <span class="title">Distributions for Discrete RVs</span>
</h3>
<div class="para" id="p-454">The first thing we do with a random variable, usually, is talk about the probabilities associate with it.</div>
<article class="definition definition-like" id="def-RVdistribution"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.5</span><span class="period">.</span>
</h4>
<div class="para" id="p-455">Given a discrete RV <span class="process-math">\(X\text{,}\)</span> its <dfn class="terminology">distribution</dfn> is a list of all of the values <span class="process-math">\(X\)</span> takes on, together with the probability of it taking that value.</div></article><div class="para" id="p-456">[Note this is quite similar to Definition <a href="" class="xref" data-knowl="./knowl/def-distribution.html" title="Definition 1.3.5">Definition¬†1.3.5</a> ‚Äî because it is essentially the same thing.]</div>
<article class="example example-like" id="eg-distribution1"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-distribution1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.6</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-distribution1"><article class="example example-like"><div class="para" id="p-457">Let‚Äôs look at the RV, which we will call <span class="process-math">\(X\text{,}\)</span> in the silly betting game of Example <a href="" class="xref" data-knowl="./knowl/eg-RV1.html" title="Example 4.3.2">Example¬†4.3.2</a>. As we noticed when we first defined that game, there are two possible values for this RV, $5 and -$5. We can actually think of ‚Äú<span class="process-math">\(X=5\)</span>‚Äù as describing an event, consisting of the set of all outcomes of the coin-flipping experiment which give you a net gain of $5. Likewise, ‚Äú<span class="process-math">\(X=-5\)</span>‚Äù describes the event consisting of the set of all outcomes which give you a net gain of -$5. These events are as follows:</div> <div class="para" id="p-458"><em class="emphasis">[Table showing: <span class="process-math">\(x\)</span> column with values 5 and -5, and corresponding outcomes column with {H} and {T}]</em></div> <div class="para" id="p-459">Since it is a fair coin so the probabilities of these events are known (and very simple), we conclude that the distribution of this RV is the table</div> <div class="para" id="p-460"><em class="emphasis">[Distribution table: <span class="process-math">\(x\)</span> = 5 with <span class="process-math">\(P(X=x) = 1/2\text{,}\)</span> and <span class="process-math">\(x\)</span> = -5 with <span class="process-math">\(P(X=x) = 1/2\)</span>]</em></div></article></div>
<article class="example example-like" id="eg-distribution2"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-distribution2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.7</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-distribution2"><article class="example example-like"><div class="para" id="p-461">What about the <span class="process-math">\(X=\text{``sum of the face values''}\)</span> RV on the ‚Äú<em class="emphasis">roll two fair dice, independently</em>‚Äù random experiment from Example <a href="" class="xref" data-knowl="./knowl/eg-RV3.html" title="Example 4.3.4">Example¬†4.3.4</a>? We have actually already done most of the work, finding out what values the RV can take and which outcomes cause each of those values. To summarize what we found:</div> <div class="para" id="p-462"><em class="emphasis">[Table showing outcomes for each sum value from 2 to 12]</em></div> <div class="para" id="p-463">But we have seen that this is an equiprobable situation, where the probability of any event <span class="process-math">\(A\)</span> contain <span class="process-math">\(n\)</span> outcomes is <span class="process-math">\(P(A)=n\cdot1/36\text{,}\)</span> so we can instantly fill in the distribution table for this RV as</div> <div class="para" id="p-464"><em class="emphasis">[Distribution table showing probabilities:<div class="displaymath process-math" id="md-17">
\begin{align*}
x=2: &amp; P(X=x) = \frac{1}{36}\\
x=3: &amp; P(X=x) = \frac{2}{36}=\frac{1}{18}\\
x=4: &amp; P(X=x) = \frac{3}{36}=\frac{1}{12}\\
x=5: &amp; P(X=x) = \frac{4}{36}=\frac{1}{6}\\
x=6: &amp; P(X=x) = \frac{5}{36}\\
x=7: &amp; P(X=x) = \frac{6}{36}=\frac{1}{6}\\
x=8: &amp; P(X=x) = \frac{5}{36}\\
x=9: &amp; P(X=x) = \frac{4}{36}=\frac{1}{6}\\
x=10: &amp; P(X=x) = \frac{3}{36}=\frac{1}{12}\\
x=11: &amp; P(X=x) = \frac{2}{36}=\frac{1}{18}\\
x=12: &amp; P(X=x) = \frac{1}{36}
\end{align*}
</div>]</em></div></article></div>
<div class="para" id="p-465">One thing to notice about distributions is that if we make a preliminary table, as we just did, of the events consisting of all outcomes which give a particular value when plugged into the RV, then we will have a collection of disjoint events which exhausts all of the sample space. What this means is that the sum of the probability values in the distribution table of an RV is the probability of the whole sample space of that RV‚Äôs experiment. Therefore</div>
<article class="assemblage assemblage-like" id="fact-distssum2one"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-466">The sum of the probabilities in a distribution table for a random variable must always equal <span class="process-math">\(1\text{.}\)</span>
</div></article><div class="para" id="p-467">It is quite a good idea, whenever you write down a distribution, to check that this Fact is true in your distribution table, simply as a sanity check against simple arithmetic errors.</div></section><section class="subsection" id="ssec-expectation4DRVs"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.3</span> <span class="title">Expectation for Discrete RVs</span>
</h3>
<div class="para" id="p-468">Since we cannot predict what exactly will be the outcome each time we perform a random experiment, we cannot predict with precision what will be the value of an RV on that experiment, each time. But, as we did with the basic idea of probability, maybe we can at least learn something from the long-term trends. It turns out that it is relatively easy to figure out the mean value of an RV over a large number of runs of the experiment.</div>
<div class="para logical" id="p-469">
<div class="para">Say <span class="process-math">\(X\)</span> is a discrete RV, for which the distribution tells us that <span class="process-math">\(X\)</span> takes the values <span class="process-math">\(x_1, \dots, x_n\text{,}\)</span> each with corresponding probability <span class="process-math">\(p_1, \dots, p_n\text{.}\)</span> Then the frequentist view of probability says that the probability <span class="process-math">\(p_i\)</span> that <span class="process-math">\(X=x_i\)</span> is (approximately) <span class="process-math">\(n_i/N\text{,}\)</span> where <span class="process-math">\(n_i\)</span> is the number of times <span class="process-math">\(X=x_i\)</span> out of a large number <span class="process-math">\(N\)</span> of runs of the experiment. But if</div>
<div class="displaymath process-math">
\begin{equation*}
p_i = n_i/N
\end{equation*}
</div>
<div class="para">then, multiplying both sides by <span class="process-math">\(N\text{,}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
n_i = p_i\,N \ .
\end{equation*}
</div>
<div class="para">That means that, out of the <span class="process-math">\(N\)</span> runs of the experiment, <span class="process-math">\(X\)</span> will have the value <span class="process-math">\(x_1\)</span> in <span class="process-math">\(p_1\,N\)</span> runs, the value <span class="process-math">\(x_2\)</span> in <span class="process-math">\(p_2\,N\)</span> runs, <em class="emphasis">etc.</em> So the sum of <span class="process-math">\(X\)</span> over those <span class="process-math">\(N\)</span> runs will be</div>
<div class="displaymath process-math">
\begin{equation*}
(p_1\,N)x_1+(p_2\,N)x_2 + \dots + (p_n\,N)x_n\ .
\end{equation*}
</div>
<div class="para">Therefore the mean value of <span class="process-math">\(X\)</span> over these <span class="process-math">\(N\)</span> runs will be the total divided by <span class="process-math">\(N\text{,}\)</span> which is <span class="process-math">\(p_1\,x_1 + \dots + p_n x_n\text{.}\)</span> This motivates the definition</div>
</div>
<article class="definition definition-like" id="def-expectation"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.8</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-470">
<div class="para">Given a discrete RV <span class="process-math">\(X\)</span> which takes on the values <span class="process-math">\(x_1, \dots, x_n\)</span> with probabilities <span class="process-math">\(p_1, \dots, p_n\text{,}\)</span> the <dfn class="terminology">expectation</dfn> [sometimes also called the <dfn class="terminology">expected value</dfn>] of <span class="process-math">\(X\)</span> is the value</div>
<div class="displaymath process-math">
\begin{equation*}
E(X) = \sum p_i\,x_i\ .
\end{equation*}
</div>
</div></article><div class="para" id="p-471">By what we saw just before this definition, we have the following</div>
<article class="assemblage assemblage-like" id="fact-RVmean"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-472">The expectation of a discrete RV is the mean of its values over many runs of the experiment.</div></article><div class="para" id="p-473">
<em class="emphasis">Note:</em> The attentive reader will have noticed that we dealt above only with the case of a finite RV, not the case of a countably infinite one. It turns out that all of the above works quite well in that more complex case as well, so long as one is comfortable with a bit of mathematical technology called ‚Äú<em class="emphasis">summing an infinite series</em>.‚Äù We do not assume such a comfort level in our readers at this time, so we shall pass over the details of expectations of infinite, discrete RVs.</div>
<article class="example example-like" id="eg-expect1"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-expect1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.9</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-expect1"><article class="example example-like"><div class="para logical" id="p-474">
<div class="para">Let‚Äôs compute the expectation of net profit RV <span class="process-math">\(X\)</span> in the silly betting game of Example <a href="" class="xref" data-knowl="./knowl/eg-RV1.html" title="Example 4.3.2">Example¬†4.3.2</a>, whose distribution we computed in Example <a href="" class="xref" data-knowl="./knowl/eg-distribution1.html" title="Example 4.3.6">Example¬†4.3.6</a>. Plugging straight into the definition, we see</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg-RV1.html ./knowl/eg-distribution1.html">
\begin{equation*}
E(X)=\sum p_i\,x_i = \frac12\cdot5 + \frac12\cdot(-5)=2.5-2.5 = 0 \ .
\end{equation*}
</div>
<div class="para">In other words, your average net gain playing this silly game many times will be <dfn class="terminology">zero</dfn>. Note that does not mean anything like ‚Äú<em class="emphasis">if you lose enough times in a row, the chances of starting to win again will go up</em>,‚Äù as many gamblers seem to believe, it just means that, in the very long run, we can expect the average winnings to be approximately zero ‚Äî but no one knows how long that run has to be before the balancing of wins and losses happens.</div>
</div></article></div>
<div class="para" id="p-475">A more interesting example is</div>
<article class="example example-like" id="eg-expect2"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-expect2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.10</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-expect2"><article class="example example-like"><div class="para logical" id="p-476">
<div class="para">In Example <a href="" class="xref" data-knowl="./knowl/eg-distribution2.html" title="Example 4.3.7">Example¬†4.3.7</a> we computed the distribution of the random variable <span class="process-math">\(X=\text{``sum of the face values''}\)</span> on the ‚Äú<em class="emphasis">roll two fair dice, independently</em>‚Äù random experiment from Example <a href="" class="xref" data-knowl="./knowl/eg-RV3.html" title="Example 4.3.4">Example¬†4.3.4</a>. It is therefore easy to plug the values of the probabilities and RV values from the distribution table into the formula for expectation, to get</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg-distribution2.html ./knowl/eg-RV3.html" id="md-18">
\begin{align*}
E(X) &amp;=\sum p_i\,x_i\\
&amp;= \frac1{36}\cdot2 + \frac2{36}\cdot3 + \frac3{36}\cdot4 + \frac4{36}\cdot5 + \frac5{36}\cdot6 + \frac6{36}\cdot7 + \frac5{36}\cdot8\\
&amp;\hphantom{= \frac1{36}\cdot2 + \frac2{36}\cdot3 + \frac3{36}\cdot4 + \frac4{36}\cdot5 + \frac5{36}\cdot6 + \frac6{36}\cdot7 + \frac5{36}\cdot8\ } + \frac4{36}\cdot9 + \frac3{36}\cdot10 + \frac2{36}\cdot11 + \frac1{36}\cdot12\\
&amp;= \frac{2\cdot1 + 3\cdot2 + 4\cdot3 + 5\cdot4 + 6\cdot5 + 7\cdot6 + 8\cdot5 + 9\cdot4 + 10\cdot3 + 11\cdot2 + 12\cdot1}{36}\\
&amp;= 7
\end{align*}
</div>
<div class="para">So if you roll two fair dice independently and add the numbers which come up, then do this process many times and take the average, in the long run that average will be the value <span class="process-math">\(7\text{.}\)</span>
</div>
</div></article></div></section><section class="subsection" id="ssec-DF4CRVs"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.4</span> <span class="title">Density Functions for Continuous RVs</span>
</h3>
<div class="para" id="p-477">What about continuous random variables? Definition <a href="" class="xref" data-knowl="./knowl/def-RVdistribution.html" title="Definition 4.3.5">Definition¬†4.3.5</a> of <em class="emphasis">distribution</em> explicitly excluded the case of continuous RVs, so does that mean we cannot do probability calculations in that case?</div>
<div class="para" id="p-478">There is, when we think about it, something of a problem here. A distribution is supposed to be a list of possible values of the RV and the probability of each such value. But if some continuous RV has values which are an interval of real numbers, there is just no way to list all such numbers ‚Äî it has been known since the late 1800s that there is no way to make a list like that. In addition, the chance of some random process producing a real number that is <em class="emphasis">exactly</em> equal to some particular value really is zero: for two real numbers to be precisely equal requires infinite accuracy ‚Ä¶ think of all of those decimal digits, marching off in orderly rows to infinity, which must match between the two numbers.</div>
<div class="para" id="p-479">Rather than a distribution, we do the following:</div>
<article class="definition definition-like" id="def-densitycurve"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.11</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-480">
<div class="para">Let <span class="process-math">\(X\)</span> be a continuous random variable whose values are the real interval <span class="process-math">\([x_{min},x_{max}]\text{,}\)</span> where either <span class="process-math">\(x_{min}\)</span> or <span class="process-math">\(x_{max}\)</span> or both may be <span class="process-math">\(\infty\text{.}\)</span> A [<dfn class="terminology">probability</dfn>] <dfn class="terminology">density function</dfn> for <span class="process-math">\(X\)</span> is a function <span class="process-math">\(f(x)\)</span> defined for <span class="process-math">\(x\)</span> in <span class="process-math">\([x_{min},x_{max}]\text{,}\)</span> meaning it is a curve with one <span class="process-math">\(y\)</span> value for each <span class="process-math">\(x\)</span> in that interval, with the property that</div>
<div class="displaymath process-math">
\begin{equation*}
P(a&lt;X&lt;b) = \left\{\begin{matrix}\text{the area in the } xy\text{-plane above the } x\text{-axis,}\\
\text{below the curve } y=f(x) \text{ and between } x=a \text{ and } x=b.\end{matrix}\right.\ .
\end{equation*}
</div>
</div></article><div class="para" id="p-481">Graphically, what is going on here is</div>
<div class="para" id="p-482"><em class="emphasis">[Figure: A probability density function showing the area under the curve between <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> representing <span class="process-math">\(P(a&lt;X&lt;b)\)</span>]</em></div>
<div class="para" id="p-483">Because of what we know about probabilities, the following is true (and fairly easy to prove):</div>
<article class="assemblage assemblage-like" id="fact-probDistFuncts"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-484">Suppose <span class="process-math">\(f(x)\)</span> is a density function for the continuous RV <span class="process-math">\(X\)</span> defined on the real interval <span class="process-math">\([x_{min},x_{max}]\text{.}\)</span> Then</div></article><div class="para" id="p-487">If we want the idea of <em class="emphasis">picking a real number on the interval <span class="process-math">\([x_{min},x_{max}]\)</span> at random</em>, where <em class="emphasis">at random</em> means that all numbers have the same chance of being picked (along the lines of <em class="emphasis">fair</em> in Definition <a href="" class="xref" data-knowl="./knowl/def-fair.html" title="Definition 4.1.18">Definition¬†4.1.18</a>, the height of the density function must be the same at all <span class="process-math">\(x\text{.}\)</span> In other words, the density function <span class="process-math">\(f(x)\)</span> must be a constant <span class="process-math">\(c\text{.}\)</span> In fact, because of the above <a href="" class="xref" data-knowl="./knowl/fact-probDistFuncts.html" title="Assemblage: Fact">Fact</a>, that constant must have the value <span class="process-math">\(\frac1{x_{max}-x_{min}}\text{.}\)</span> There is a name for this:</div>
<article class="definition definition-like" id="def-uniformdistr"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.12</span><span class="period">.</span>
</h4>
<div class="para" id="p-488">The <dfn class="terminology">uniform distribution on <span class="process-math">\([x_{min},x_{max}]\)</span></dfn> is the distribution for the continuous RV whose values are the interval <span class="process-math">\([x_{min},x_{max}]\)</span> and whose density function is the constant function <span class="process-math">\(f(x)=\frac1{x_{max}-x_{min}}\text{.}\)</span>
</div></article><article class="example example-like" id="eg-unifdistr1"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-unifdistr1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.13</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-unifdistr1"><article class="example example-like"><div class="para" id="p-489">Suppose you take a bus to school every day and because of a chaotic home life (and, let‚Äôs face it, you don‚Äôt like mornings), you get to the bus stop at a pretty nearly perfectly random time. The bus also doesn‚Äôt stick perfectly to its schedule ‚Äî but it is guaranteed to come at least every <span class="process-math">\(30\)</span> minutes. What this adds up to is the idea that your waiting time at the bus stop is a uniformly distributed RV on the interval <span class="process-math">\([0,30]\text{.}\)</span>
</div> <div class="para logical" id="p-490">
<div class="para">If you wonder one morning how likely it then is that you will wait for less than <span class="process-math">\(10\)</span> minutes, you can simply compute the area of the rectangle whose base is the interval <span class="process-math">\([0,10]\)</span> on the <span class="process-math">\(x\)</span>-axis and whose height is <span class="process-math">\(\frac1{30}\text{,}\)</span> which will be</div>
<div class="displaymath process-math">
\begin{equation*}
P(0&lt;X&lt;10)=\text{base}\cdot\text{height}=10\cdot\frac1{30}=\frac13\ .
\end{equation*}
</div>
</div> <div class="para" id="p-491"><em class="emphasis">[Figure: Bus waiting time uniform distribution showing shaded area from 0 to 10 minutes]</em></div> <div class="para" id="p-492">where the area of the shaded region represents the probability of having a waiting time from <span class="process-math">\(0\)</span> to <span class="process-math">\(10\)</span> minutes.</div></article></div>
<div class="para logical" id="p-493">
<div class="para">One technical thing that can be confusing about continuous RVs and their density functions is the question of whether we should write <span class="process-math">\(P(a&lt;X&lt;b)\)</span> or <span class="process-math">\(P(a\le X\le b)\text{.}\)</span> But if you think about it, we really have three possible events here:</div>
<div class="displaymath process-math" id="md-19">
\begin{align*}
A &amp;= \{\text{outcomes such that } X=a\},\\
M &amp;= \{\text{outcomes such that } a&lt;X&lt;b\},\text{ and}\\
B &amp;= \{\text{outcomes such that } X=b\}\ .
\end{align*}
</div>
<div class="para">Since <span class="process-math">\(X\)</span> always takes on exactly one value for any particular outcome, there is no overlap between these events: they are all disjoint. That means that</div>
<div class="displaymath process-math">
\begin{equation*}
P(A\cup M\cup B) = P(A)+P(M)+P(B) = P(M)
\end{equation*}
</div>
<div class="para">where the last equality is because, as we said above, the probability of a continuous RV taking on exactly one particular value, as it would in events <span class="process-math">\(A\)</span> and <span class="process-math">\(B\text{,}\)</span> is <span class="process-math">\(0\text{.}\)</span> The same would be true if we added merely one endpoint of the interval <span class="process-math">\((a,b)\text{.}\)</span> To summarize:</div>
</div>
<article class="assemblage assemblage-like" id="fact-LTvsLE4cRVs"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para logical" id="p-494">
<div class="para">If <span class="process-math">\(X\)</span> is a continuous RV with values forming the interval <span class="process-math">\([x_{min},x_{max}]\)</span> and <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> are in this interval, then</div>
<div class="displaymath process-math">
\begin{equation*}
P(a&lt;X&lt;b) = P(a&lt;X\le b) = P(a\le X&lt;b) = P(a\le X\le b)\ .
\end{equation*}
</div>
</div></article><div class="para" id="p-495">As a consequence of this fact, some authors write probability formul√¶ about continuous RVs with ‚Äú<span class="process-math">\(&lt;\)</span>‚Äù and some with ‚Äú<span class="process-math">\(\le\)</span>‚Äù and <em class="emphasis">it makes no difference</em>.</div>
<div class="para" id="p-496">Let‚Äôs do a slightly more interesting example than the uniform distribution:</div>
<article class="example example-like" id="eg-triangleDistr"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-triangleDistr"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.14</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-triangleDistr"><article class="example example-like"><div class="para" id="p-497">Suppose you repeatedly throw darts at a dartboard. You‚Äôre not a machine, so the darts hit in different places every time and you think of this as a repeatable random experiment whose outcomes are the locations of the dart on the board. You‚Äôre interested in the probabilities of getting close to the center of the board, so you decide for each experimental outcome (location of a dart you threw) to measure its distance to the center ‚Äî this will be your RV <span class="process-math">\(X\text{.}\)</span>
</div> <div class="para" id="p-498">Being good at this game, you hit near the center more than near the edge and you never completely miss the board, whose radius is <span class="process-math">\(10cm\)</span> ‚Äî so <span class="process-math">\(X\)</span> is more likely to be near <span class="process-math">\(0\)</span> than near <span class="process-math">\(10\text{,}\)</span> and it is never greater than <span class="process-math">\(10\text{.}\)</span> What this means is that the RV has values forming the interval <span class="process-math">\([0,10]\)</span> and the density function, defined on the same interval, should have its maximum value at <span class="process-math">\(x=0\)</span> and should go down to the value <span class="process-math">\(0\)</span> when <span class="process-math">\(x=10\text{.}\)</span>
</div> <div class="para" id="p-499">You decide to model this situation with the simplest density function you can think of that has the properties we just noticed: a straight line from the highest point of the density function when <span class="process-math">\(x=0\)</span> down to the point <span class="process-math">\((10,0)\text{.}\)</span> The figure that will result will be a triangle, and since the total area must be <span class="process-math">\(1\)</span> and the base is <span class="process-math">\(10\)</span> units long, the height must be <span class="process-math">\(.2\)</span> units. [To get that, we solved the equation <span class="process-math">\(1=\frac12bh=\frac1210h=5h\)</span> for <span class="process-math">\(h\text{.}\)</span>] So the graph must be</div> <div class="para" id="p-500"><em class="emphasis">[Figure: Triangular density function for dart hitting distance]</em></div> <div class="para" id="p-501">and the equation of this linear density function would be <span class="process-math">\(y=-\frac1{50}x+.2\)</span> [why? ‚Äî think about the slope and <span class="process-math">\(y\)</span>-intercept!].</div> <div class="para" id="p-502">To the extent that you trust this model, you can now calculate the probabilities of events like, for example, ‚Äú<em class="emphasis">hitting the board within that center bull‚Äôs-eye of radius <span class="process-math">\(1.5cm\)</span></em>,‚Äù which probability would be the area of the shaded region in this graph:</div> <div class="para" id="p-503"><em class="emphasis">[Figure: Dart hitting bull‚Äôs-eye probability shown as shaded trapezoid]</em></div> <div class="para logical" id="p-504">
<div class="para">The upper-right corner of this shaded region is at <span class="process-math">\(x\)</span>-coordinate <span class="process-math">\(1.5\)</span> and is on the line, so its <span class="process-math">\(y\)</span>-coordinate is <span class="process-math">\(-\frac1{50}1.5+.2=.17\text{.}\)</span> Since the region is a trapezoid, its area is the distance between the two parallel sides times the average of the lengths of the other two sides, giving</div>
<div class="displaymath process-math">
\begin{equation*}
P(0&lt;X&lt;1.5) = 1.5\cdot\frac{.2+.17}2 = .2775\ .
\end{equation*}
</div>
<div class="para">In other words, the probability of hitting the bull‚Äôs-eye, assuming this model of your dart-throwing prowess, is about <span class="process-math">\(28\)</span>%.</div>
</div> <div class="para" id="p-505">If you don‚Äôt remember the formula for the area of a trapezoid, you can do this problem another way: compute the probability of the complementary event, and then take one minus that number. The reason to do this would be that the complementary event corresponds to the shaded region here</div> <div class="para" id="p-506"><em class="emphasis">[Figure: Complementary event showing triangular region]</em></div> <div class="para logical" id="p-507">
<div class="para">which is a triangle! Since we surely do remember the formula for the area of a triangle, we find that</div>
<div class="displaymath process-math">
\begin{equation*}
P(1.5&lt;X&lt;10)=\frac12bh=\frac{1}{2}.17\cdot8.5=.7225
\end{equation*}
</div>
<div class="para">and therefore <span class="process-math">\(P(0&lt;X&lt;1.5)=1-P(1.5&lt;X&lt;10)=1-.7225=.2775\text{.}\)</span> [It‚Äôs nice that we got the same number this way, too!]</div>
</div></article></div></section><section class="subsection" id="ssec-TND"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.5</span> <span class="title">The Normal Distribution</span>
</h3>
<div class="para" id="p-508">We‚Äôve seen some examples of continuous RVs, but we have yet to meet the most important one of all.</div>
<article class="definition definition-like" id="def-generalNormalDist"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.15</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-509">
<div class="para">The <dfn class="terminology">Normal distribution with mean <span class="process-math">\(\mu_X\)</span> and standard deviation <span class="process-math">\(\sigma_X\)</span></dfn> is the continuous RV which takes on all real values and is governed by the probability density function</div>
<div class="displaymath process-math">
\begin{equation*}
\rho(x)=\frac1{\sqrt{2\sigma_X^2\pi}}e^{-\frac{(x-\mu_X)^2}{2\sigma_X^2}}\ .
\end{equation*}
</div>
<div class="para">If <span class="process-math">\(X\)</span> is a random variable which follows this distribution, then we say that <dfn class="terminology"><span class="process-math">\(X\)</span> is Normally distributed with mean <span class="process-math">\(\mu_X\)</span> and standard deviation <span class="process-math">\(\sigma_X\)</span></dfn> or, in symbols, <dfn class="terminology"><span class="process-math">\(X\)</span> is <span class="process-math">\(N(\mu_X, \sigma_X)\)</span></dfn>.</div>
</div></article><div class="para" id="p-510">[More technical works also call this the <em class="emphasis">Gaussian distribution</em>, named after the great mathematician <em class="emphasis">Carl Friedrich Gauss</em>. But we will not use that term again in this book after this sentence ends.]</div>
<div class="para" id="p-511">The good news about this complicated formula is that we don‚Äôt really have to do anything with it. We will collect some properties of the Normal distribution which have been derived from this formula, but these properties are useful enough, and other tools such as modern calculators and computers which can find specific areas we need under the graph of <span class="process-math">\(y=\rho(x)\text{,}\)</span> that we won‚Äôt need to work directly with the above formula for <span class="process-math">\(\rho(x)\)</span> again. It is nice to know that <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> does correspond to a specific, known density function, though, isn‚Äôt it?</div>
<div class="para" id="p-512">It helps to start with an image of what the Normal distribution looks like. Here is the density function for <span class="process-math">\(\mu_X=17\)</span> and <span class="process-math">\(\sigma_X=3\text{:}\)</span>
</div>
<div class="para" id="p-513"><em class="emphasis">[Figure: Normal distribution with mean 17 and standard deviation 3]</em></div>
<div class="para" id="p-514">Now let‚Äôs collect some of these useful facts about the Normal distributions.</div>
<article class="assemblage assemblage-like" id="fact-NormalIsDensityFcn"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-515">The density function <span class="process-math">\(\rho\)</span> for the Normal distribution <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> is a positive function for all values of <span class="process-math">\(x\)</span> and the total area under the curve <span class="process-math">\(y=\rho(x)\)</span> is <span class="process-math">\(1\text{.}\)</span>
</div></article><div class="para" id="p-516">This simply means that <span class="process-math">\(\rho\)</span> is a good candidate for the probability density function for some continuous RV.</div>
<article class="assemblage assemblage-like" id="fact-NormalIsUnimodal"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-517">The density function <span class="process-math">\(\rho\)</span> for the Normal distribution <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> is unimodal with maximum at <span class="process-math">\(x\)</span>-coordinate <span class="process-math">\(\mu_X\text{.}\)</span>
</div></article><div class="para" id="p-518">This means that <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> is a possible model for an RV <span class="process-math">\(X\)</span> which tends to have one main, central value, and less often has other values farther away. That center is at the location given by the parameter <span class="process-math">\(\mu_X\text{,}\)</span> so wherever we want to put the center of our model for <span class="process-math">\(X\text{,}\)</span> we just use that for <span class="process-math">\(\mu_X\text{.}\)</span>
</div>
<article class="assemblage assemblage-like" id="fact-NormalIsSymmetric"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-519">The density function <span class="process-math">\(\rho\)</span> for the Normal distribution <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> is is symmetric when reflected across the line <span class="process-math">\(x=\mu_X\text{.}\)</span>
</div></article><div class="para" id="p-520">This means that the amount <span class="process-math">\(X\)</span> misses its center, <span class="process-math">\(\mu_X\text{,}\)</span> tends to be about the same when it misses above <span class="process-math">\(\mu_X\)</span> and when it misses below <span class="process-math">\(\mu_X\text{.}\)</span> This would correspond to situations were you hit as much to the right as to the left of the center of a dartboard. Or when randomly picked people are as likely to be taller than the average height as they are to be shorter. Or when the time it takes a student to finish a standardized test is as likely to be less than the average as it is to be more than the average. Or in many, many other useful situations.</div>
<article class="assemblage assemblage-like" id="fact-NormalHasThinTails"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-521">The density function <span class="process-math">\(\rho\)</span> for the Normal distribution <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> has has tails in both directions which are quite thin, in fact get extremely thin as <span class="process-math">\(x\to\pm\infty\text{,}\)</span> but never go all the way to <span class="process-math">\(0\text{.}\)</span>
</div></article><div class="para" id="p-522">This means that <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> models situations where the amount <span class="process-math">\(X\)</span> deviates from its average has no particular cut-off in the positive or negative direction. So you are throwing darts at a dart board, for example, and there is no way to know how far your dart may hit to the right or left of the center, maybe even way off the board and down the hall ‚Äî although that may be very unlikely. Or perhaps the time it takes to complete some task is usually a certain amount, but every once and a while it might take much more time, so much more that there is really no natural limit you might know ahead of time.</div>
<div class="para" id="p-523">At the same time, those tails of the Normal distribution are so thin, for values far away from <span class="process-math">\(\mu_X\text{,}\)</span> that it can be a good model even for a situation where there is a natural limit to the values of <span class="process-math">\(X\)</span> above or below <span class="process-math">\(\mu_X\text{.}\)</span> For example, heights of adult males (in inches) in the United States are fairly well approximated by <span class="process-math">\(N(69, 2.8)\text{,}\)</span> even though heights can never be less than <span class="process-math">\(0\)</span> and <span class="process-math">\(N(69, 2.8)\)</span> has an infinitely long tail to the left ‚Äî because while that tail is non-zero all the way as <span class="process-math">\(x\to-\infty\text{,}\)</span> it is very, very thin.</div>
<div class="para" id="p-524">All of the above Facts are clearly true on the first graph we saw of a Normal distribution density function.</div>
<article class="assemblage assemblage-like" id="fact-NormalEffectOfSigma"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-525">The graph of the density function <span class="process-math">\(\rho\)</span> for the Normal distribution <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> has a taller and narrower peak if <span class="process-math">\(\sigma_X\)</span> is smaller, and a lower and wider peak if <span class="process-math">\(\sigma_X\)</span> is larger.</div></article><div class="para" id="p-526">This allows the statistician to adjust how much variation there typically is in a normally distributed RV: By making <span class="process-math">\(\sigma_X\)</span> small, we are saying that an RV <span class="process-math">\(X\)</span> which is <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> is very likely to have values quite close to its center, <span class="process-math">\(\mu_X\text{.}\)</span> If we make <span class="process-math">\(\sigma_X\)</span> large, however, <span class="process-math">\(X\)</span> is more likely to have values all over the place ‚Äî still, centered at <span class="process-math">\(\mu_X\text{,}\)</span> but more likely to wander farther away.</div>
<div class="para" id="p-527">Let‚Äôs make a few versions of the graph we saw for <span class="process-math">\(\rho\)</span> when <span class="process-math">\(\mu_X\)</span> was <span class="process-math">\(17\)</span> and <span class="process-math">\(\sigma_X\)</span> was <span class="process-math">\(3\text{,}\)</span> but now with different values of <span class="process-math">\(\sigma_X\text{.}\)</span> First, if <span class="process-math">\(\sigma_X=1\text{,}\)</span> we get</div>
<div class="para" id="p-528"><em class="emphasis">[Figure: Normal distribution with mean 17 and standard deviation 1]</em></div>
<div class="para" id="p-529">If, instead, <span class="process-math">\(\sigma_X=5\text{,}\)</span> then we get</div>
<div class="para" id="p-530"><em class="emphasis">[Figure: Normal distribution with mean 17 and standard deviation 5]</em></div>
<div class="para" id="p-531">Finally, let‚Äôs superimpose all of the above density functions on each other, for one, combined graph:</div>
<div class="para" id="p-532"><em class="emphasis">[Figure: Three Normal distributions with mean 17 and standard deviations 1, 3, and 5 superimposed]</em></div>
<div class="para" id="p-533">This variety of Normal distributions (one for each <span class="process-math">\(\mu_X\)</span> and <span class="process-math">\(\sigma_X\)</span>) is a bit bewildering, so traditionally, we concentrate on one particularly nice one.</div>
<article class="definition definition-like" id="def-standardNormalDist"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.16</span><span class="period">.</span>
</h4>
<div class="para" id="p-534">The Normal distribution with mean <span class="process-math">\(\mu_X=0\)</span> and standard deviation <span class="process-math">\(\sigma_X=1\)</span> is called the <dfn class="terminology">standard Normal distribution</dfn> and an RV [often written with the variable <span class="process-math">\(Z\)</span>] that is <span class="process-math">\(N(0, 1)\)</span> is described as a <dfn class="terminology">standard Normal RV</dfn>.</div></article><div class="para" id="p-535">Here is what the standard Normal probability density function looks like:</div>
<div class="para" id="p-536"><em class="emphasis">[Figure: Standard Normal distribution with mean 0 and standard deviation 1]</em></div>
<div class="para" id="p-537">One nice thing about the standard Normal is that all other Normal distributions can be related to the standard.</div>
<article class="assemblage assemblage-like" id="fact-standardization"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-538">If <span class="process-math">\(X\)</span> is <span class="process-math">\(N(\mu_X, \sigma_X)\text{,}\)</span> then <span class="process-math">\(Z=(X-\mu_X)/\sigma_X\)</span> is standard Normal.</div></article><div class="para" id="p-539">This has a name.</div>
<article class="definition definition-like" id="def-standardization"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.17</span><span class="period">.</span>
</h4>
<div class="para" id="p-540">The process of replacing a random variable <span class="process-math">\(X\)</span> which is <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> with the standard normal RV <span class="process-math">\(Z=(X-\mu_X)/\sigma_X\)</span> is called <dfn class="terminology">standardizing a Normal RV</dfn>.</div></article><div class="para" id="p-541">It used to be that standardization was an important step in solving problems with Normal RVs. A problem would be posed with information about some data that was modelled by a Normal RV with given mean <span class="process-math">\(\mu_X\)</span> and standardization <span class="process-math">\(\sigma_X\text{.}\)</span> Then questions about probabilities for that data could be answered by standardizing the RV and looking up values in a single table of areas under the standard Normal curve.</div>
<div class="para" id="p-542">Today, with electronic tools such as statistical calculators and computers, the standardization step is not really necessary.</div>
<article class="example example-like" id="eg-normalcomp"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-normalcomp"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.18</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-normalcomp"><article class="example example-like"><div class="para" id="p-543">As we noted above, the heights of adult men in the United States, when measured in inches, give a RV <span class="process-math">\(X\)</span> which is <span class="process-math">\(N(69, 2.8)\text{.}\)</span> What percentage of the population, then, is taller than <span class="process-math">\(6\)</span> feet?</div> <div class="para" id="p-544">First of all, the frequentist point of view on probability tells us that what we are interested in is the probability that a randomly chosen adult American male will be taller than <span class="process-math">\(6\)</span> feet ‚Äî that will be the same as the percentage of the population this tall. In other words, we must find the probability that <span class="process-math">\(X&gt;72\text{,}\)</span> since in inches, <span class="process-math">\(6\)</span> feet becomes <span class="process-math">\(72\text{.}\)</span> As <span class="process-math">\(X\)</span> is a continuous RV, we must find the area under its density curve, which is the <span class="process-math">\(\rho\)</span> for <span class="process-math">\(N(69, 2.8)\text{,}\)</span> between <span class="process-math">\(72\)</span> and <span class="process-math">\(\infty\text{.}\)</span>
</div> <div class="para" id="p-545">That <span class="process-math">\(\infty\)</span> is a little intimidating, but since the tails of the Normal distribution are very thin, we can stop measuring area when <span class="process-math">\(x\)</span> is some large number and we will have missed only a very tiny amount of area, so we will have a very good approximation. Let‚Äôs therefore find the area under <span class="process-math">\(\rho\)</span> from <span class="process-math">\(x=72\)</span> up to <span class="process-math">\(x=1000\text{.}\)</span> This can be done in many ways:</div> <ul class="disc">
<li id="li-42"><div class="para" id="p-546">With a wide array of online tools ‚Äî just search for ‚Äúonline normal probability calculator.‚Äù One of these yields the value <span class="process-math">\(.142\text{.}\)</span>
</div></li>
<li id="li-43"><div class="para logical" id="p-547">
<div class="para">With a <dfn class="terminology">TI-8x</dfn> calculator, by typing</div>
<div class="displaymath process-math">
\begin{equation*}
\text{normalcdf(72, 1000, 69, 2.8)}
\end{equation*}
</div>
<div class="para"> which yields the value <span class="process-math">\(.1419884174\text{.}\)</span> The general syntax here is</div>
<div class="displaymath process-math">
\begin{equation*}
\text{normalcdf}(a, b, \mu_X, \sigma_X)
\end{equation*}
</div>
<div class="para">to find <span class="process-math">\(P(a&lt;X&lt;b)\)</span> when <span class="process-math">\(X\)</span> is <span class="process-math">\(N(\mu_X, \sigma_X)\text{.}\)</span> Note you get <dfn class="terminology">normalcdf</dfn> by typing [2ND] ‚Üí [VARS] ‚Üí 2</div>
</div></li>
<li id="li-44">
<div class="para logical" id="p-548">
<div class="para">Spreadsheets like <dfn class="terminology">LibreOffice Calc</dfn> and <dfn class="terminology">Microsoft Excel</dfn> will compute this by putting the following in a cell</div>
<div class="displaymath process-math">
\begin{equation*}
\text{=1-NORM.DIST(72, 69, 2.8, 1)}
\end{equation*}
</div>
<div class="para"> giving the value 0.1419883859. Here we are using the command</div>
<div class="displaymath process-math">
\begin{equation*}
\text{NORM.DIST}(b, \mu_X, \sigma_X, 1)
\end{equation*}
</div>
<div class="para">which computes the area under the density function for <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> from <span class="process-math">\(-\infty\)</span> to <span class="process-math">\(b\text{.}\)</span> [The last input of ‚Äú1‚Äù to NORM.DIST just tells it that we want to compute the area under the curve. If we used ‚Äú0‚Äù instead, it would simple tell us the particular value of <span class="process-math">\(\rho(b)\text{,}\)</span> which is of very direct little use in probability calculations.] Therefore, by doing <span class="process-math">\(1-NORM.DIST(72, 69, 2.8, 1)\text{,}\)</span> we are taking the total area of 1 and subtracting the area to the left of 72, yielding the area to the right, as we wanted.</div>
</div>
<div class="para logical" id="p-549">
<div class="para">Therefore, if you want the area between <span class="process-math">\(a\)</span> and <span class="process-math">\(b\)</span> on an <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> RV using a spreadsheet, you would put</div>
<div class="displaymath process-math">
\begin{equation*}
\text{=NORM.DIST}(b, \mu_X, \sigma_X, 1) - \text{NORM.DIST}(a, \mu_X, \sigma_X, 1)
\end{equation*}
</div>
<div class="para">in a cell.</div>
</div>
</li>
</ul></article></div>
<div class="para" id="p-550">While standardizing a non-standard Normal RV and then looking up values in a table is an old-fashioned method that is tedious and no longer really needed, one old technique still comes in handy some times. It is based on the following:</div>
<article class="assemblage assemblage-like" id="fact-68-95-99-7"><h4 class="heading"><span class="title">Fact.</span></h4>
<div class="para" id="p-551">
<dfn class="terminology">The 68-95-99.7 Rule</dfn>: Let <span class="process-math">\(X\)</span> be an <span class="process-math">\(N(\mu_X, \sigma_X)\)</span> RV. Then some special values of the area under the graph of the density curve <span class="process-math">\(\rho\)</span> for <span class="process-math">\(X\)</span> are nice to know:</div></article><div class="para" id="p-555">This is also called <dfn class="terminology">The Empirical Rule</dfn> by some authors. Visually:</div>
<div class="para" id="p-556"><em class="emphasis">[Figure: The 68-95-99.7 Rule illustrated on a Normal distribution curve]</em></div>
<div class="para" id="p-557">In order to use the 68-95-99.7 Rule in understanding a particular situation, it is helpful to keep an eye out for the numbers that it talks about. Therefore, when looking at a problem, one should notice if the numbers <span class="process-math">\(\mu_X+\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X-\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X+2\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X-2\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X+3\sigma_X\text{,}\)</span> or <span class="process-math">\(\mu_X-3\sigma_X\)</span> are ever mentioned. If so, perhaps this Rule can help.</div>
<article class="example example-like" id="eg-use68-95-99-7-1"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-use68-95-99-7-1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.19</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-use68-95-99-7-1"><article class="example example-like"><div class="para logical" id="p-558">
<div class="para">In Example <a href="" class="xref" data-knowl="./knowl/eg-normalcomp.html" title="Example 4.3.18">Example¬†4.3.18</a>, we needed to compute <span class="process-math">\(P(X&gt;72)\)</span> where <span class="process-math">\(X\)</span> was known to be <span class="process-math">\(N(69, 2.8)\text{.}\)</span> Is 72 one of the numbers for which we should be looking, to use the Rule? Well, it‚Äôs greater than <span class="process-math">\(\mu_X=69\text{,}\)</span> so we could hope that it was <span class="process-math">\(\mu_X+\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X+2\sigma_X\text{,}\)</span> or <span class="process-math">\(\mu_X+3\sigma_X\text{.}\)</span> But values are</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg-normalcomp.html" id="md-20">
\begin{align*}
\mu_X+\sigma_X&amp;=69+2.8=71.8,\\
\mu_X+2\sigma_X&amp;=69+5.6=74.6, \text{ and}\\
\mu_X+3\sigma_X&amp;=69+8.4=77.4,
\end{align*}
</div>
<div class="para">none of which is what we need.</div>
</div> <div class="para" id="p-559">Well, it is true that <span class="process-math">\(72\approx71.8\text{,}\)</span> so we could use that fact and accept that we are only getting an approximate answer ‚Äî an odd choice, given the availability of tools which will give us extremely precise answers, but let‚Äôs just go with it for a minute.</div> <div class="para logical" id="p-560">
<div class="para">Let‚Äôs see, the above Rule tells us that</div>
<div class="displaymath process-math">
\begin{equation*}
P(66.2&lt;X&lt;71.8)=P(\mu_X-\sigma_X&lt;X&lt;\mu_X+\sigma_X)=.68\ .
\end{equation*}
</div>
<div class="para">Now since the total area under any density curve is 1,</div>
<div class="displaymath process-math">
\begin{equation*}
P(X&lt;66.2\text{ or }X&gt;71.8) = 1 - P(66.2&lt;X&lt;71.8) = 1- .68 = .32\ .
\end{equation*}
</div>
<div class="para">Since the event ‚Äú<span class="process-math">\(X&lt;66.2\)</span>‚Äù is disjoint from the event ‚Äú<span class="process-math">\(X&gt;71.8\)</span>‚Äù (<span class="process-math">\(X\)</span> only takes on one value at a time, so it cannot be simultaneously less than 66.2 and greater than 71.8), we can use the simple rule for addition of probabilities:</div>
<div class="displaymath process-math">
\begin{equation*}
.32 = P(X&lt;66.2\text{ or }X&gt;71.8) = P(X&lt;66.2) + P(X&gt;71.8)\ .
\end{equation*}
</div>
<div class="para">Now, since the density function of the Normal distribution is symmetric around the line <span class="process-math">\(x=\mu_X\text{,}\)</span> the two terms on the right in the above equation are equal, which means that</div>
<div class="displaymath process-math">
\begin{equation*}
P(X&gt;71.8) = \frac12\left(P(X&lt;66.2) + P(X&gt;71.8)\right) = \frac12 .32 = .16\ .
\end{equation*}
</div>
<div class="para">It might help to visualize the symmetry here as the equality of the two shaded areas in the following graph</div>
</div> <div class="para" id="p-561"><em class="emphasis">[Figure: Symmetric shaded areas showing equal tail probabilities]</em></div> <div class="para logical" id="p-562">
<div class="para">Now, using the fact that <span class="process-math">\(72\approx71.8\text{,}\)</span> we may say that</div>
<div class="displaymath process-math">
\begin{equation*}
P(X&gt;72)\approx P(X&gt;71.8) = .16
\end{equation*}
</div>
<div class="para">which, since we know that in fact <span class="process-math">\(P(X&gt;72)=.1419883859\text{,}\)</span> is not a completely terrible approximation.</div>
</div></article></div>
<article class="example example-like" id="eg-use68-95-99-7-2"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-use68-95-99-7-2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.20</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-use68-95-99-7-2"><article class="example example-like"><div class="para" id="p-563">Let‚Äôs do one more computation in the context of the heights of adult American males, as in the immediately above Example <a href="" class="xref" data-knowl="./knowl/eg-use68-95-99-7-1.html" title="Example 4.3.19">Example¬†4.3.19</a>, but now one in which the 68-95-99.7 Rule gives a more precise answer.</div> <div class="para" id="p-564">So say we are asked this time what proportion of adult American men are shorter than 63.4 inches. Why that height, in particular? Well, it‚Äôs how tall archaeologists have determined King Tut was in life. [No, that‚Äôs made up. It‚Äôs just a good number for this problem.]</div> <div class="para logical" id="p-565">
<div class="para">Again, looking through the values <span class="process-math">\(\mu_X\pm\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X\pm2\sigma_X\text{,}\)</span> and <span class="process-math">\(\mu_X\pm3\sigma_X\text{,}\)</span> we notice that</div>
<div class="displaymath process-math">
\begin{equation*}
63.4=69-5.6=\mu_X-2\sigma_X\ .
\end{equation*}
</div>
<div class="para">Therefore, to answer what fraction of adult American males are shorter than 63.4 inches amounts to asking what is the value of <span class="process-math">\(P(X&lt;\mu_X-2\sigma_X)\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-566">
<div class="para">What we know about <span class="process-math">\(\mu_X\pm2\sigma_X\)</span> is that the probability of <span class="process-math">\(X\)</span> being between those two values is <span class="process-math">\(P(\mu_X-2\sigma_X&lt;X&lt;\mu_X+2\sigma_X)=.95\text{.}\)</span> As in the previous Example, the complementary event to ‚Äú<span class="process-math">\(\mu_X-2\sigma_X&lt;X&lt;\mu_X+2\sigma_X\text{,}\)</span>‚Äù which will have probability <span class="process-math">\(.05\text{,}\)</span> consists of two pieces ‚Äú<span class="process-math">\(X&lt;\mu_X-2\sigma_X\)</span>‚Äù and ‚Äú<span class="process-math">\(X&gt;\mu_X+2\sigma_X\text{,}\)</span>‚Äù which have the same area by symmetry. Therefore</div>
<div class="displaymath process-math" id="md-21">
\begin{align*}
P(X&lt;63.4)&amp;=P(X&lt;\mu_X-2\sigma_X)\\
&amp;=\frac12\left[P(X&lt;\mu_X-2\sigma_X)+P(X&gt;\mu_X+2\sigma_X)\right]\\
&amp;=\frac12P(X&lt;\mu_X-2\sigma_X\text{ or }X&gt;\mu_X+2\sigma_X)\text{ since they're disjoint}\\
&amp;=\frac12P((\mu_X-2\sigma_X&lt;X&lt;\mu_X+2\sigma_X)^c)\\
&amp;=\frac12\left[1-P(\mu_X-2\sigma_X&lt;X&lt;\mu_X+2\sigma_X)\right]\text{ by prob. for complements}\\
&amp;=\frac12\,.05\\
&amp;=.025
\end{align*}
</div>
</div></article></div>
<div class="para" id="p-567">Just the way finding the particular <span class="process-math">\(X\)</span> values <span class="process-math">\(\mu_X\pm\sigma_X\text{,}\)</span> <span class="process-math">\(\mu_X\pm2\sigma_X\text{,}\)</span> and <span class="process-math">\(\mu_X\pm3\sigma_X\)</span> in a particular situation would tell us the 68-95-99.7 Rule might be useful, so also would finding the probability values <span class="process-math">\(.68\text{,}\)</span> <span class="process-math">\(.95\text{,}\)</span> <span class="process-math">\(99.7\text{,}\)</span> or their complements <span class="process-math">\(.32\text{,}\)</span> <span class="process-math">\(.05\text{,}\)</span> or <span class="process-math">\(.003\text{,}\)</span> ‚Äî or even half of one of those numbers, using the symmetry.</div>
<article class="example example-like" id="eg-use68-95-99-7-3"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg-use68-95-99-7-3"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.21</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg-use68-95-99-7-3"><article class="example example-like"><div class="para" id="p-568">Continuing with the scenario of Example <a href="" class="xref" data-knowl="./knowl/eg-use68-95-99-7-1.html" title="Example 4.3.19">Example¬†4.3.19</a>, let us now figure out what is the height above which there will only be .15% of the population.</div> <div class="para" id="p-569">Notice that .15%, or the proportion .0015, is not one of the numbers in the 68-95-99.7 Rule, nor is it one of their complements ‚Äî but it is half of one of the complements, being half of .003. Now, .003 is the complementary probability to .997, which was the probability in the range <span class="process-math">\(\mu_X\pm3\sigma_X\text{.}\)</span> As we have seen already (twice), the complementary area to that in the region between <span class="process-math">\(\mu_X\pm3\sigma_X\)</span> consists of two thin tails which are of equal area, each of these areas being <span class="process-math">\(\frac12(1-.997)=.0015\text{.}\)</span> This all means that the beginning of that upper tail, above which value lies .15% of the population, is the <span class="process-math">\(X\)</span> value <span class="process-math">\(\mu_X+3\sigma_X = 68 + 3\cdot2.8 = 77.4\text{.}\)</span>
</div> <div class="para" id="p-570">Therefore .15% of adult American males are taller than 77.4 inches.</div></article></div></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="sec-condprob.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="sec-probability-exercises.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
